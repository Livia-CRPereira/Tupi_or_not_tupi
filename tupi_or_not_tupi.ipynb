{"cells":[{"cell_type":"markdown","metadata":{"id":"94d2suAm6-3g"},"source":["# ‚åõ Montando o drive + Carregamento dos dados:\n","- Sugest√£o : vamos todas deixar o trabalho na pasta MyDrive, pois desse modo n√£o temos problema com caminho!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gfTd8yVqLy7H","colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"status":"error","timestamp":1765060523196,"user_tz":180,"elapsed":121041,"user":{"displayName":"Sophia Vieira","userId":"05527157961171224908"}},"outputId":"4f8264c3-9853-4f19-affb-3c0915d79a48"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"mount failed","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2805143318.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# O caminho depende onde o atalho da pasta est√° no seu computador. Mudar para cada uma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["import pandas as pd\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# O caminho depende onde o atalho da pasta est√° no seu computador. Mudar para cada uma\n","caminho_livia = '/content/drive/MyDrive/'\n","caminho_ruas = '/content/drive/MyDrive/'\n","caminho_rosa = ''\n","caminho_sophia = '/content/drive/MyDrive/'\n","# Mudar para o seu caminho:\n","folder_path = '/content/drive/MyDrive/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LB2lgYF_767O","collapsed":true},"outputs":[],"source":["! pip install geopandas geobr plotly rpy2"]},{"cell_type":"markdown","metadata":{"id":"INpwfnmbQ1Uw"},"source":["# üìÇ Carregamento dos dados completos\n","‚ö† SE A PARTE 1 J√Å FOI FEITA E OS DADOS FORAM CONSOLIDADOS, PARA O CARREGAMENTO PARA A REALIZA√á√ÉO DAS OUTRAS PARTES DO PROJETO, CARREGUE NO PR√ìXIMO BLOCO (CARREGAMENTO DOS DADOS CONSOLIDADOS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ITXioM7E6ogb"},"outputs":[],"source":["vigilancia_alimentar_2019 = pd.read_csv(folder_path + 'projeto_icd/data_base/vigilancia_alimentar_2019.csv', sep=';')\n","vigilancia_alimentar_2020 = pd.read_csv(folder_path + 'projeto_icd/data_base/vigilancia_alimentar_2020.csv', sep=';')\n","vigilancia_alimentar_2021 = pd.read_csv(folder_path + 'projeto_icd/data_base/vigilancia_alimentar_2021.csv', sep=';')\n","vigilancia_alimentar_2022 = pd.read_csv(folder_path + 'projeto_icd/data_base/vigilancia_alimentar_2022.csv', sep=';')\n","\n","prenatal_2019 = pd.read_csv(folder_path + 'projeto_icd/data_base/prenatal_microdados_2019.csv', sep=';')\n","prenatal_2020 = pd.read_csv(folder_path + 'projeto_icd/data_base/prenatal_microdados_2020.csv', sep=';')\n","prenatal_2021 = pd.read_csv(folder_path + 'projeto_icd/data_base/prenatal_microdados_2021.csv', sep=';')\n","prenatal_2022 = pd.read_csv(folder_path + 'projeto_icd/data_base/prenatal_microdados_2022.csv', sep=';')\n","\n","acompanhamento_2019 = pd.read_csv(folder_path + 'projeto_icd/data_base/acompanhamento_2019.csv', sep=';')\n","acompanhamento_2020 = pd.read_csv(folder_path + 'projeto_icd/data_base/acompanhamento_2020.csv', sep=';')\n","acompanhamento_2021 = pd.read_csv(folder_path + 'projeto_icd/data_base/acompanhamento_2021.csv', sep=';')\n","acompanhamento_2022 = pd.read_csv(folder_path + 'projeto_icd/data_base/acompanhamento_2022.csv', sep=';')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bCqzAIh5Bx5a"},"outputs":[],"source":["vigilancia_dfs = {\n","    2019: vigilancia_alimentar_2019,\n","    2020: vigilancia_alimentar_2020,\n","    2021: vigilancia_alimentar_2021,\n","    2022: vigilancia_alimentar_2022\n","}\n","\n","acompanhamento_dfs = {\n","    2019: acompanhamento_2019,\n","    2020: acompanhamento_2020,\n","    2021: acompanhamento_2021,\n","    2022: acompanhamento_2022\n","}\n","\n","prenatal_dfs = {\n","    2019: prenatal_2019,\n","    2020: prenatal_2020,\n","    2021: prenatal_2021,\n","    2022: prenatal_2022\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B4wdnvWAD2k1"},"outputs":[],"source":["print(vigilancia_alimentar_2019.columns, acompanhamento_2019.columns, prenatal_2019.columns)"]},{"cell_type":"markdown","metadata":{"id":"aqZ3C8eoSKf6"},"source":["# üìÇ Carregamento dos dados consolidados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mKtU-ctBSSUS"},"outputs":[],"source":["#CARREGAR OS DADOS J√Å LIMPOS\n","\n","# 1. Carregar os dados das crian√ßas\n","print(\"Carregando 'dados_consolidados_criancas.csv'...\")\n","#  Quando se usa CSV, as datas s√£o lidas como texto.\n","colunas_data_criancas = ['dt_atendimento', 'dt_nascimento']\n","df_criancas = pd.read_csv(folder_path + 'projeto_icd/data_base/dados_consolidados_criancas.csv', parse_dates=colunas_data_criancas)\n","print(\"-> DataFrame das crian√ßas carregado!\")\n","\n","\n","# 2. Carregar os dados do pr√©-natal\n","print(\"\\nCarregando 'dados_consolidados_prenatal.csv'...\")\n","colunas_data_prenatal = ['dt_nascimento', 'dt_ultima_menstruacao', 'dt_finalizacao', 'dt_acompanhamento']\n","df_prenatal = pd.read_csv(folder_path + 'projeto_icd/data_base/dados_consolidados_prenatal.csv', parse_dates=colunas_data_prenatal)\n","print(\"-> DataFrame do pr√©-natal carregado!\")\n","\n","\n","# Verificando as informa√ß√µes para confirmar que tudo carregou corretamente\n","print(\"\\n--- Informa√ß√µes do DataFrame de Crian√ßas ---\")\n","df_criancas.info()\n","\n","print(\"\\n--- Informa√ß√µes do DataFrame de Pr√©-Natal ---\")\n","df_prenatal.info()"]},{"cell_type":"markdown","metadata":{"id":"vuyLekk3AUmz"},"source":["# üìä Plano de a√ß√£o\n","\n","**Data de In√≠cio:** 24/08/2025\n","**Equipe:** Let√≠cia Ruas, Let√≠cia Rosa, Sophia, L√≠via\n","**Objetivo:** Analisar os determinantes da sa√∫de e nutri√ß√£o de crian√ßas ind√≠genas a partir dos bancos de dados SIASI, identificando padr√µes geogr√°ficos, fatores de risco para desnutri√ß√£o e o impacto de vari√°veis sociodemogr√°ficas e de cuidado no crescimento infantil.\n","\n","-----\n","## Fase 0: Defini√ß√£o do tema (Prazo: 02/10) ‚úÖ\n","### 0.1. Encontrar base (Prazo: 02/10) ‚úÖ\n","### 0.2. Definir perguntas (Prazo: 02/10) ‚úÖ\n","\n","## Fase 1: Prepara√ß√£o e Limpeza dos Dados\n","\n","Esta fase √© a funda√ß√£o de todo o projeto. O objetivo √© criar um √∫nico DataFrame mestre, limpo e pronto para an√°lise.\n","\n","### 1.1. Limpeza e Padroniza√ß√£o de Valores Nulos (Prazo: 02/10) ‚úÖ\n","\n","  * **Tarefa:** Substituir todas as representa√ß√µes de dados ausentes por um padr√£o √∫nico (`np.nan`).\n","  * **M√©todo:**\n","      * Criar uma lista de valores a serem substitu√≠dos: `['DESCONHECIDO', 'SEM INFORMA√á√ÉO', 'N√ÉO SE APLICA']`.\n","      * Aplicar a fun√ß√£o `df.replace(lista_nulos, np.nan, inplace=True)` no DataFrame consolidado.\n","      * Usar `df.fillna('DESCONHECIDO', inplace=True)` nas colunas de c√≥digo onde \"Desconhecido\" √© uma categoria relevante e n√£o aus√™ncia de informa√ß√£o.\n","\n","### 1.2. Convers√£o de Tipos de Dados (Type Casting)(Prazo: 02/10) ‚úÖ\n","\n","  * **Tarefa:** Garantir que cada coluna tenha o tipo de dado correto para an√°lise.\n","  * **M√©todo:**\n","      * **Num√©rico:** Converter `nu_peso` e `nu_altura` para `float`. Ser√° necess√°rio primeiro substituir a v√≠rgula `,` por ponto `.`.\n","        ```python\n","        df['nu_peso'] = df['nu_peso'].str.replace(',', '.').astype(float)\n","        ```\n","      * **Categ√≥rico:** Converter colunas de texto com poucas categorias (ex: `tp_sexo`, `ds_peso_idade`) para o tipo `category` para otimizar o uso de mem√≥ria.\n","      * **Data:** Assegurar que todas as colunas de data (`dt_...`) est√£o no formato `datetime64[ns]`.\n","\n","`Entrevista 1: 02/10`\n","\n","### 1.3. Consolida√ß√£o dos DataFrames (Prazo: 16/10) ‚úÖ\n","\n","  * **Tarefa:** Unificar `df_vigilancia_final`, `df_acompanhamento_final`, e `df_prenatal_final` em um √∫nico DataFrame.\n","  * **M√©todo:** Investigar as colunas de chave (provavelmente `co_indio_desidentificado` e outras chaves sequenciais) para realizar a jun√ß√£o (`merge`) das tabelas. √â preciso definir o tipo de join (provavelmente `outer` ou `left`) para n√£o perder registros.\n","\n","\n","### 1.4. Engenharia de Vari√°veis (Prazo: 16/10) ‚úÖ\n","\n","  * **Tarefa:** Criar novas vari√°veis que ser√£o √∫teis para responder √†s perguntas.\n","  * **M√©todo:**\n","      * **Idade:** Se ainda n√£o existir, criar uma coluna `idade_anos` calculada a partir de `dt_nascimento` e `dt_atendimento`.\n","\n","-----\n","\n","## Fase 2: An√°lise Explorat√≥ria de Dados (EDA) - **Caracteriza√ß√£o** (Prazo: 25/10)\n","\n","Com a base limpa, o objetivo desta fase √© \"sentir\" os dados, encontrar padr√µes iniciais e validar hip√≥teses.\n","\n","### 2.1. Perguntas Explorat√≥rias Adicionais (Prazo: 25/10) ‚úÖ\n","\n","  * **RQ1**: Qual a preval√™ncia dos principais diagn√≥sticos nutricionais (`ds_peso_idade`, `ds_estatura_idade`) na popula√ß√£o ind√≠gena?\n","  * Como se distribuem as idades e o sexo na amostra?\n","  * Quais s√£o os tipos de aleitamento mais comuns?\n","  * Quais os profissionais de sa√∫de (`ds_cbo_familia`) que mais realizam atendimentos?\n","\n","### 2.2. An√°lise Univariada (Prazo: 06/11) ‚úÖ\n","\n","  * **Tarefa:** Analisar cada vari√°vel individualmente.\n","  * **M√©todo:**\n","      * **Vari√°veis Num√©ricas (`nu_peso`, `nu_altura`, `idade_meses_atend`):** Gerar histogramas e boxplots para visualizar a distribui√ß√£o e identificar outliers. Calcular estat√≠sticas descritivas (`.describe()`).\n","      * **Vari√°veis Categ√≥ricas (`dsei_gestao`, `tipo_aleitamento`, etc.):** Gerar gr√°ficos de barras (`.value_counts().plot(kind='bar')`) para ver a frequ√™ncia de cada categoria.\n","\n","### 2.3. RQ2: Distribui√ß√£o Geogr√°fica dos Indicadores (Prazo: 25/10) ‚úÖ\n","\n","  * **Pergunta:** Como os principais indicadores de sa√∫de infantil se distribuem geograficamente entre os diferentes DSEIs?\n","  * **Plano:**\n","    1.  Agrupar os dados por `dsei_gestao`.\n","    2.  Para cada DSEI, calcular a preval√™ncia de cada categoria de `ds_peso_idade` e `ds_estatura_idade` (ex: % de baixo peso, % de estatura adequada).\n","    3.  Visualizar os resultados em um **gr√°fico de barras ordenado** para cada indicador, mostrando os DSEIs com as melhores e piores taxas.\n","    4.  (Avan√ßado) Se houver dados geogr√°ficos (shapefiles) dos DSEIs, criar um **mapa coropl√©tico** para visualizar a preval√™ncia de desnutri√ß√£o no territ√≥rio.\n","\n","-----\n","\n","## Fase 3: An√°lise Bivariada e Modelagem\n","\n","Nesta fase, responderemos diretamente √†s perguntas de pesquisa.\n","\n","### 3.1. An√°lise Bivariada - **Teste de Hip√≥teses/IC 1** (Prazo: 06/11)\n","\n","  * **Tarefa:** Investigar a rela√ß√£o entre pares de vari√°veis.\n","  * **M√©todo:**\n","      * `nu_altura` vs. `idade_meses_atend` (gr√°fico de dispers√£o) para visualizar o crescimento.\n","      * `tipo_aleitamento` vs. `nu_altura` (tabela de conting√™ncia `pd.crosstab` ou gr√°fico de barras agrupado).\n","      * Investigar se existe diferen√ßa estatisticamente significativa entre as m√©dias de `nu_altura` entre os sexos (`tp_sexo`) - **Teste de Hip√≥teses 1** usando Teste T.\n","\n","\n","### 3.2. RQ3: Aleitamento e Estado Nutricional - **Teste de Hip√≥teses/IC 2** (Prazo: 06/11)\n","\n","* **Pergunta:** O tipo de aleitamento materno est√° relacionado ao estado nutricional (avaliado pela classifica√ß√£o de **peso para idade**) das crian√ßas?\n","* **Plano:**\n","    1.  Utilizar as colunas `tipo_aleitamento` e `ds_peso_idade` do DataFrame consolidado.\n","    2.  Criar uma tabela de conting√™ncia (`pd.crosstab`) entre a coluna `tipo_aleitamento` e a coluna `ds_peso_idade`.\n","    3.  Aplicar o **Teste Qui-Quadrado de Independ√™ncia** (`scipy.stats.chi2_contingency`) sobre essa tabela.\n","    4.  Analisar o p-valor. Se for menor que um n√≠vel de signific√¢ncia (ex: 0.05), podemos concluir que existe uma associa√ß√£o estatisticamente significativa entre as vari√°veis.\n","\n","`Entrevista 2: 06/11`\n","\n","(Regress√£o)\n","\n","### 3.4. RQ4: Impacto Combinado no Crescimento - **Regress√£o Linear** (Prazo: 24/11)\n","\n","* **Pergunta:** Qual o impacto combinado de diferentes vari√°veis no crescimento (altura) das crian√ßas ind√≠genas?\n","* **Plano:**\n","    1.  **Fase 1: Prepara√ß√£o de Dados (Python/Pandas)** ‚úÖ\n","        * Utilizar o DataFrame `df_criancas`.\n","        * **Definir Vari√°vel Alvo (Y):** `nu_altura` (j√° limpa).\n","        * **Selecionar Candidatas a Preditoras (X):**\n","        * **Limpeza:** Selecionar apenas as colunas necess√°rias e usar `.dropna()` para garantir um dataset completo, sem valores ausentes.\n","\n","    2.  **Fase 2: Modelagem (R via rpy2)**\n","        * Transferir o DataFrame limpo (`df_altura_pronto`) do Python para o R.\n","        * No R, converter as vari√°veis categ√≥ricas para `factor`.\n","        * **Construir o Modelo:** Usar a fun√ß√£o `lm()` para rodar a **Regress√£o Linear M√∫ltipla**:\n","            `lm(nu_altura ~ idade_meses_atend + tp_sexo + ...)`\n","        * **Analisar Resultados:** Usar `summary()` no R. Interpretar os coeficientes (ex: \"a cada m√™s de idade, a altura aumenta X cm\"), o R-quadrado e os p-valores para entender o impacto de cada fator no crescimento.\n","\n","> RQ4 pode ser usada para o trabalho de regress√£o. A data de entrega dele √© `26/11`.\n","\n","-----\n","\n","## Fase 4: Consolida√ß√£o e Relat√≥rio Final (Prazo: 26/11)\n","\n","  * **Tarefa:** Reunir todas as an√°lises, gr√°ficos e conclus√µes.\n","  * **M√©todo:**\n","    1.  Escrever um resumo dos achados (cada pessoa pode ficar respons√°vel por um peda√ßo)\n","    2.  A equipe se reunir√° para discutir os resultados e montar uma narrativa coesa.\n","    3.  Elaborar um relat√≥rio final (ou Jupyter Notebook) que apresente o problema, a metodologia, os resultados e as conclus√µes do estudo.\n","\n","`Entrevista 3: 06/12`\n","\n","`Entrega do Relat√≥rio: 05/12`\n","-----"]},{"cell_type":"markdown","metadata":{"id":"l1hNcsFjOfjM"},"source":["# üìä Resumo dos DataFrames\n","\n","### `df_vigilancia_final`\n","\n","Este DataFrame cont√©m os registros de **Vigil√¢ncia Alimentar e Nutricional (VAN)** para crian√ßas ind√≠genas menores de 5 anos. √â a fonte principal para dados antropom√©tricos (peso e altura) e diagn√≥sticos nutricionais.\n","\n","#### Colunas Principais de Uso\n","* `dsei_gestao`, `sg_uf`, `no_municipio`: **Localiza√ß√£o geogr√°fica** do atendimento, sendo `dsei_gestao` o principal agrupador geogr√°fico para as an√°lises.\n","* `dt_nascimento`, `tp_sexo`: **Dados demogr√°ficos** b√°sicos da crian√ßa.\n","* `dt_atendimento`, `idade_meses_atend`: **Informa√ß√µes sobre o atendimento**, cruciais para an√°lises temporais e de crescimento.\n","* `nu_peso`, `nu_altura` (float): **Medidas antropom√©tricas** da crian√ßa em kg e cm, respectivamente. J√° foram limpas e convertidas para o formato num√©rico.\n","* `ds_peso_idade`, `ds_estatura_idade`, `ds_imc_idade` (category): **Diagn√≥sticos nutricionais**, que s√£o as vari√°veis-alvo para entender a desnutri√ß√£o. Classificam a crian√ßa com base nos par√¢metros da OMS 111].\n","* `tipo_aleitamento` (category): **Tipo de aleitamento materno**, uma vari√°vel explicativa chave para as suas perguntas de pesquisa.\n","\n","#### Colunas de Identifica√ß√£o e Contexto\n","* **`co_...`** (string): C√≥digos de identifica√ß√£o para DSEI, polo base, munic√≠pio, indiv√≠duo, profissionais, etc. S√£o √∫teis principalmente para cruzamentos (`merge`) com outras bases de dados.\n","* `ds_polo_base`, `no_terra_indigena`: N√≠veis geogr√°ficos mais granulares que o DSEI.\n","* `ds_tipo_acomp_nutricional`, `ds_cbo_familia`, `ds_cbo_ocupacao`: Descrevem o tipo de atendimento e quem o realizou. Podem ser usadas como vari√°veis de contexto.\n","* **`..._outlier`** (bool): Colunas de controle geradas durante a limpeza, indicando se o registro foi considerado um outlier em alguma etapa.\n","\n","### `df_acompanhamento_final`\n","\n","Este DataFrame registra os atendimentos de **acompanhamento de rotina de sa√∫de** (baseado no CID Z00.1) para crian√ßas ind√≠genas **menores de 1 ano**, 16]. Sua principal finalidade √© o registro de morbidades.\n","\n","#### Colunas Principais de Uso\n","* `co_indio_desidentificado` (string): **Identificador √∫nico da crian√ßa**, essencial para conectar este DataFrame aos outros* `dsei_gestao`, `sg_uf`: **Localiza√ß√£o geogr√°fica** do atendimento* `dt_atendimento`, `idade_atend_em_dias`: **Data e idade no momento do atendimento**\n","* `co_cid10`, `no_categoria_subcategoria`: **A informa√ß√£o central deste DataFrame**. Cont√©m o c√≥digo da doen√ßa ou condi√ß√£o registrada (CID-10)Ser√° usada para responder √† pergunta sobre a rela√ß√£o entre aleitamento e doen√ßas diarreicas.\n","* `faixa_etaria_atend`: Faixa et√°ria da crian√ßa em dias, √∫til para agrupar an√°lises\n","\n","#### Colunas de Identifica√ß√£o e Contexto\n","* **`co_...`** (string): C√≥digos de DSEI, polo, terra ind√≠gena, munic√≠pio, etc., para fins de cruzamento.\n","* `ds_polo_base`, `no_terra_indigena`: Nomes correspondentes aos c√≥digos geogr√°ficos.\n","* `co_seq_morbidade`: C√≥digo √∫nico para cada registro de morbidade* `ds_cbo_...`: Informa√ß√µes sobre o profissional que realizou o atendimento. Conforme o dicion√°rio, apenas registros de m√©dicos e enfermeiros s√£o considerados \"Consulta de Crescimento e Desenvolvimento\"\n","* **`..._outlier`** (bool): Colunas de controle da etapa de limpeza.\n","\n","### `df_prenatal_final`\n","\n","Este DataFrame cont√©m os registros de **acompanhamento gestacional** de mulheres ind√≠genas, com gesta√ß√µes finalizadas entre 2019 e 2022.\n","\n","#### Colunas Principais de Uso\n","* `co_indio_desidentificado` (string): **Identificador √∫nico da gestante**, permitindo o cruzamento com outros dados da mesma pessoa (se dispon√≠veis)\n","* `co_gestacao_desidentificado` (string): **Identificador √∫nico para cada gesta√ß√£o**, importante caso uma mesma mulher tenha mais de uma gesta√ß√£o no per√≠odo\n","* `dt_ultima_menstruacao`, `dt_finalizacao`, `dt_acompanhamento`: **Datas chave** que definem o per√≠odo gestacional e os momentos de cuidado\n","* `st_risco_gestacional` (category): Classifica√ß√£o do risco da gesta√ß√£o (Alto/Baixo), uma importante vari√°vel de sa√∫de\n","* `st_motivo_finalizacao` (category): Motivo do t√©rmino da gesta√ß√£o (Nascimento, Aborto, etc.), uma vari√°vel de desfecho crucial\n","* `dsei_gestao`: **Localiza√ß√£o geogr√°fica** do DSEI de gest√£o\n","\n","#### Colunas de Identifica√ß√£o e Contexto\n","* **`co_...`** (string): C√≥digos de identifica√ß√£o diversos (DSEI, polo, munic√≠pio, profissional).\n","* `ds_polo_base`, `no_terra_indigena`: Nomes geogr√°ficos.\n","* `co_seq_acompanhamento_gestacao`: C√≥digo √∫nico para cada consulta/acompanhamento dentro de uma mesma gesta√ß√£o\n","* `tp_local_atendimento`: Onde o atendimento foi realizado (Aldeia, Polo Base, etc.)\n","* `ds_cbo_...`: Informa√ß√µes sobre os profissionais que realizaram o acompanhamento.\n","* `ano_outlier` (bool): Coluna de controle da limpeza.\n"]},{"cell_type":"markdown","metadata":{"id":"cbAvV4QYRneq"},"source":["# üò≤ Parte 1"]},{"cell_type":"markdown","metadata":{"id":"FXCmi7JCMxn6"},"source":["## 1.1 Consolida√ß√£o e Limpeza Inicial:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FRr97TLWM2VZ"},"outputs":[],"source":["#concateno os df, pois o m√©todo concat usa o √≠ndice dos dicion√°rios para criar um novo √≠ndice\n","#transformo o index (nosso caso √© o ano) em uma coluna comum, agora temos uma coluna de ano\n","#o concat usa as chaves do dicion√°rio(√≠ndices) para criar o index mais extremo nesse caso o ano (level 0)\n","df_vigilancia = pd.concat(vigilancia_dfs).reset_index(level=0).rename(columns={'level_0': 'ano'})\n","df_acompanhamento = pd.concat(acompanhamento_dfs).reset_index(level=0).rename(columns={'level_0': 'ano'})\n","df_prenatal = pd.concat(prenatal_dfs).reset_index(level=0).rename(columns={'level_0': 'ano'})\n","\n","#vou resetar o index passado, pq agora como concatenamos v√°rias base de dados, vamos ter index repetidos. cria√ß√£o de um novo index autom√°tica pelo pandas quandos jogamos um index antigo fora\n","df_vigilancia.reset_index(drop=True, inplace=True)\n","df_acompanhamento.reset_index(drop=True, inplace=True)\n","df_prenatal.reset_index(drop=True, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zuotXoCaSjSK"},"outputs":[],"source":["#vamos fazer um resumo de cada dataframe para ver o estado dele:\n","df_vigilancia.info()\n","print('-' * 80)\n","df_acompanhamento.info()\n","print('-' * 80)\n","df_prenatal.info()"]},{"cell_type":"markdown","metadata":{"id":"5X3ZFWqcUIlc"},"source":["Diagn√≥stico:\n","* Colunas que deveriam ser datas, est√£o sendo tratadas como texto!\n","* No df_vigilancia, as colunas nu_peso e nu_altura tamb√©m s√£o object.\n","* Dados Nulos:\n","    *   df_vigilancia: Apenas tipo_aleitamento tem alguns nulos. √â uma    quantidade pequena e manej√°vel.\n","\n","    *   df_acompanhamento: faixa_etaria_atend tem uma quantidade consider√°vel de nulos.\n","    \n","    * df_prenatal: √â o que mais sofre com dados faltantes, especialmente nas colunas sobre o profissional (ds_cbo_familia, ds_cbo_ocupacao) e o motivo da finaliza√ß√£o da gesta√ß√£o (st_motivo_finalizacao).\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EaoTfl7fUx11"},"outputs":[],"source":["import numpy as np\n","\n","def diagnostico_df(df, nome=\"DataFrame\"):\n","    print(\"=\"*80)\n","    print(f\"üìä Diagn√≥stico do {nome}\")\n","    print(\"=\"*80)\n","\n","    # Dimens√µes\n","    print(f\"Dimens√£o: {df.shape[0]:,} linhas √ó {df.shape[1]} colunas\\n\")\n","\n","    # Tipos de dados\n","    print(\"Tipos de dados:\")\n","    print(df.dtypes.value_counts(), \"\\n\")\n","\n","    # Valores ausentes\n","    print(\"Valores ausentes (top 10):\")\n","    missing = df.isnull().sum().sort_values(ascending=False)\n","    missing = missing[missing > 0]\n","    if not missing.empty:\n","        print((missing / len(df) * 100).round(2).astype(str) + \" %\")\n","    else:\n","        print(\"Nenhum valor ausente.\\n\")\n","\n","    # Colunas num√©ricas\n","    num_cols = df.select_dtypes(include=[np.number]).columns\n","    if len(num_cols) > 0:\n","        print(\"\\nüìà Estat√≠sticas num√©ricas:\")\n","        print(df[num_cols].describe(percentiles=[.01, .25, .5, .75, .99]).T)\n","\n","        print(\"\\nüö® Poss√≠veis outliers (limite pelo IQR):\")\n","        for col in num_cols:\n","            q1, q3 = df[col].quantile([0.25, 0.75])\n","            iqr = q3 - q1\n","            lower, upper = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n","            outliers = ((df[col] < lower) | (df[col] > upper)).sum()\n","            if outliers > 0:\n","                print(f\" - {col}: {outliers:,} outliers\")\n","    else:\n","        print(\"\\nNenhuma coluna num√©rica encontrada.\")\n","\n","    # Colunas categ√≥ricas\n","    cat_cols = df.select_dtypes(include=[\"object\"]).columns\n","    if len(cat_cols) > 0:\n","        print(\"\\nüî§ Estat√≠sticas categ√≥ricas:\")\n","        for col in cat_cols[:5]:  # mostra s√≥ as 5 primeiras para n√£o poluir\n","            print(f\"\\nColuna: {col}\")\n","            print(\"N¬∫ de categorias √∫nicas:\", df[col].nunique())\n","            print(\"Top valores:\")\n","            print(df[col].value_counts(dropna=False).head(5))\n","    print(\"\\n\\n\")\n","\n","# Rodar diagn√≥stico para os tr√™s dfs\n","diagnostico_df(df_vigilancia, \"df_vigilancia\")\n","diagnostico_df(df_acompanhamento, \"df_acompanhamento\")\n","diagnostico_df(df_prenatal, \"df_prenatal\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VdtMRCtCVyiO"},"outputs":[],"source":["import numpy as np\n","\n","def limpar_dataframe(df, nome=\"DataFrame\"):\n","    print(f\"\\nüîß Limpando {nome}...\")\n","\n","    df_clean = df.copy()\n","\n","    # 1. Converter datas automaticamente\n","    for col in df_clean.columns:\n","        if col.startswith(\"dt_\"):\n","            try:\n","                df_clean[col] = pd.to_datetime(df_clean[col], errors=\"coerce\")\n","            except Exception:\n","                print(f\"‚ö†Ô∏è Problema ao converter {col} para datetime\")\n","\n","    # 2. Reclassificar IDs e c√≥digos para string\n","    for col in df_clean.columns:\n","        if col.startswith((\"co_\", \"cod_\", \"nu_\")):\n","            df_clean[col] = df_clean[col].astype(\"string\")\n","\n","    # 3. Padronizar categorias sujas\n","    for col in df_clean.select_dtypes(include=\"object\").columns:\n","        df_clean[col] = df_clean[col].replace({\n","            \"A qualificar para valida√ß√£o\": np.nan,\n","            \"FORA DE TERRA IND√çGENA SITUADA EM √ÅREA RURAL\": \"FORA_TERRA_RURAL\",\n","            \"FORA DE TERRA IND√çGENA\": \"FORA_TERRA\"\n","        })\n","\n","    # 4. Remover espa√ßos extras e padronizar mai√∫sculas em categ√≥ricas\n","    for col in df_clean.select_dtypes(include=\"object\").columns:\n","        df_clean[col] = df_clean[col].str.strip().str.upper()\n","\n","    print(f\"‚úÖ {nome} limpo. Dimens√£o final: {df_clean.shape[0]:,} linhas √ó {df_clean.shape[1]} colunas\")\n","    return df_clean\n","\n","\n","# Aplicar nos tr√™s DataFrames\n","df_vigilancia_clean = limpar_dataframe(df_vigilancia, \"df_vigilancia\")\n","df_acompanhamento_clean = limpar_dataframe(df_acompanhamento, \"df_acompanhamento\")\n","df_prenatal_clean = limpar_dataframe(df_prenatal, \"df_prenatal\")\n","\n","# Exemplo de preview\n","print(\"\\nüìå Amostra do df_vigilancia_clean:\")\n","print(df_vigilancia_clean.head())\n","print(df_acompanhamento_clean.head())\n","print(df_prenatal_clean.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cFa9hGsyW4bF"},"outputs":[],"source":["\n","import numpy as np\n","\n","# Detecta outliers usando IQR\n","def marcar_outliers(df, col):\n","    if pd.api.types.is_numeric_dtype(df[col]):\n","        Q1 = df[col].quantile(0.25)\n","        Q3 = df[col].quantile(0.75)\n","        IQR = Q3 - Q1\n","        lim_inf = Q1 - 1.5 * IQR\n","        lim_sup = Q3 + 1.5 * IQR\n","        df[col + \"_outlier\"] = ((df[col] < lim_inf) | (df[col] > lim_sup))\n","    return df\n","\n","# Imputa valores ausentes em colunas categ√≥ricas com \"DESCONHECIDO\"\n","def imputar_categorias(df, cols):\n","    for col in cols:\n","        df[col] = df[col].fillna(\"DESCONHECIDO\")\n","    return df\n","\n","# Imputa valores ausentes em colunas num√©ricas com mediana\n","def imputar_numericos(df, cols):\n","    for col in cols:\n","        df[col] = df[col].fillna(df[col].median())\n","    return df\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0iINLAMuXfk_"},"outputs":[],"source":["def limpeza_avancada(df, nome=\"DataFrame\"):\n","    print(f\"\\n‚ö° Limpeza avan√ßada: {nome}\")\n","    df_clean = df.copy()\n","\n","    # 1. Marcar outliers em colunas num√©ricas importantes\n","    col_num = df_clean.select_dtypes(include=np.number).columns.tolist()\n","    for col in col_num:\n","        df_clean = marcar_outliers(df_clean, col)\n","\n","    # 2. Tratar valores ausentes cr√≠ticos\n","    col_categ = df_clean.select_dtypes(include=\"object\").columns.tolist()\n","    df_clean = imputar_categorias(df_clean, col_categ)\n","\n","    col_num = df_clean.select_dtypes(include=np.number).columns.tolist()\n","    df_clean = imputar_numericos(df_clean, col_num)\n","\n","    print(f\"‚úÖ Limpeza avan√ßada conclu√≠da para {nome}. Dimens√£o final: {df_clean.shape}\")\n","    return df_clean\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UpgPvFNyXh13"},"outputs":[],"source":["df_vigilancia_final = limpeza_avancada(df_vigilancia_clean, \"df_vigilancia\")\n","df_acompanhamento_final = limpeza_avancada(df_acompanhamento_clean, \"df_acompanhamento\")\n","df_prenatal_final = limpeza_avancada(df_prenatal_clean, \"df_prenatal\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eF1F4TbsDtTa"},"outputs":[],"source":["# O valor \"SEM INFORM√á√ÉO\" tamb√©m ser√° substituido por DESCONHECIDO, para uniformidade\n","valores_para_substituir = 'SEM INFORMA√á√ÉO'\n","\n","lista_dfs = [df_vigilancia_final, df_acompanhamento_final, df_prenatal_final]\n","\n","for df in lista_dfs:\n","  df.replace(valores_para_substituir, 'DESCONHECIDO', inplace=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sY0OVCuqFc8J"},"outputs":[],"source":[" #--- C√≥digo Principal para listar as colunas com NaNs ---\n","\n","lista_de_dfs = [df_vigilancia_final, df_acompanhamento_final, df_prenatal_final]\n","lista_de_nomes = ['df_vigilancia_final', 'df_acompanhamento_final', 'df_prenatal_final']\n","\n","for df, df_name in zip(lista_de_dfs, lista_de_nomes):\n","    print(\"=\"*50)\n","    print(f\"Analisando Colunas com NaNs no DataFrame: '{df_name}'\")\n","    print(\"=\"*50)\n","\n","    # Encontra as colunas que cont√™m QUALQUER valor NaN e transforma em uma lista\n","    colunas_com_nan = df.columns[df.isnull().any()].tolist()\n","\n","    if colunas_com_nan:\n","        print(f\"As seguintes colunas cont√™m valores NaN:\")\n","        print(f\"  -> {colunas_com_nan}\")\n","    else:\n","        print(\"√ìtimo! Nenhuma coluna com valores NaN foi encontrada.\")\n","\n","    print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VPWdC69UMSg_"},"outputs":[],"source":["df_acompanhamento_final['co_cbo_ocupacao'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GgJapkscGUJS"},"outputs":[],"source":["\"As colunas que mant√©m os NA s√£o de c√≥digo -  n√£o faz sentido pegar a mediana\"\n","\n","lista_dfs = [df_vigilancia_final, df_acompanhamento_final, df_prenatal_final]\n","\n","print(\"--- Preenchendo valores NaN com 'DESCONHECIDO' usando .fillna() ---\")\n","for df in lista_dfs:\n","  df.fillna('DESCONHECIDO', inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jWIy-KJUNThU"},"outputs":[],"source":["df_acompanhamento_final['co_cbo_ocupacao'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kbHtmIrcAbrz"},"outputs":[],"source":["def analise_colunas(df):\n","  for column in df.columns:\n","    print(column)\n","    print(df[column].unique())\n","\n","for df,df_name in zip(\n","                [df_vigilancia_final, df_acompanhamento_final, df_prenatal_final],\n","                 ['df_vigilancia_final', 'df_acompanhamento_final', 'df_prenatal_final']):\n","  print(df_name)\n","  analise_colunas(df)"]},{"cell_type":"markdown","metadata":{"id":"lvxt2juWQ0ZS"},"source":["## 1.2. Convers√£o de Tipos de Dados (Type Casting)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kV_ym5viQn2d"},"outputs":[],"source":["def limpar_e_tipar_dataframes(lista_de_dfs, lista_de_nomes):\n","    \"\"\"\n","    Aplica um conjunto de regras de limpeza e convers√£o de tipos\n","    a uma lista de DataFrames.\n","    \"\"\"\n","    for df, nome_df in zip(lista_de_dfs, lista_de_nomes):\n","        print(\"=\"*60)\n","        print(f\"Processando o DataFrame: '{nome_df}'\")\n","        print(\"=\"*60)\n","\n","        for coluna in df.columns:\n","            if coluna in ['nu_peso', 'nu_altura']:\n","                # Verifica se a coluna √© do tipo texto antes de tentar substituir\n","                if pd.api.types.is_string_dtype(df[coluna]):\n","                    print(f\"  - Convertendo coluna num√©rica '{coluna}' para float...\")\n","                    # Substitui v√≠rgula por ponto e converte para num√©rico\n","                    # errors='coerce' transforma valores inv√°lidos em NaN\n","                    df[coluna] = pd.to_numeric(df[coluna].str.replace(',', '.'), errors='coerce')\n","\n","            elif coluna.startswith('dt_'):\n","                # Verifica se a coluna j√° n√£o √© do tipo datetime\n","                if not pd.api.types.is_datetime64_any_dtype(df[coluna]):\n","                    print(f\"  - Convertendo coluna de data '{coluna}' para datetime...\")\n","                    # errors='coerce' transforma datas inv√°lidas em NaT (Not a Time)\n","                    df[coluna] = pd.to_datetime(df[coluna], errors='coerce')\n","\n","            elif pd.api.types.is_object_dtype(df[coluna]):\n","                num_unicos = df[coluna].nunique()\n","                # Heur√≠stica: converte se tiver menos de 50 valores √∫nicos\n","                # e se o n√∫mero de √∫nicos for menor que 50% do total de linhas.\n","                # Isso evita converter colunas de ID.\n","                if num_unicos < 50 and num_unicos / len(df) < 0.5:\n","                    print(f\"  - Convertendo coluna de texto '{coluna}' para category...\")\n","                    df[coluna] = df[coluna].astype('category')\n","        print(\"Processamento conclu√≠do.\\n\")\n","\n","\n","#Execu√ß√£o\n","\n","# Definindo as listas de DataFrames e seus nomes\n","dataframes = [df_vigilancia_final, df_acompanhamento_final, df_prenatal_final]\n","nomes_dfs = ['df_vigilancia_final', 'df_acompanhamento_final', 'df_prenatal_final']\n","\n","# Aplicando a fun√ß√£o de limpeza\n","limpar_e_tipar_dataframes(dataframes, nomes_dfs)\n","\n","\n","#Verifica√ß√£o Final\n","# Imprimindo o .info() de cada DataFrame para confirmar as mudan√ßas\n","print(\"=\"*60)\n","print(\"VERIFICA√á√ÉO FINAL DOS TIPOS DE DADOS (dtypes)\")\n","print(\"=\"*60)\n","for df, nome_df in zip(dataframes, nomes_dfs):\n","    print(f\"\\n--- {nome_df}.info() ---\")\n","    df.info()\n"]},{"cell_type":"markdown","metadata":{"id":"3wsqaG-OSYPK"},"source":["## 1.3 Consolida√ß√£o dos DataFrames\n","\n","A partir daqui, importante citar que devemos usar os seguintes data frames, que j√° est√£o limpos e consolidados com os tipos corretos:\n","\n","`df_vigilancia_final`, `df_acompanhamento_final`, `df_prenatal_final`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fok6vdpoFYeS"},"outputs":[],"source":["# Revis√£o geral dos dfs\n","# Para o DataFrame de Vigil√¢ncia\n","print(\"--- df_vigilancia_final ---\")\n","df_vigilancia_final.info()\n","print(\"\\nPrimeiras linhas:\")\n","print(df_vigilancia_final.head())\n","print(\"\\n\")\n","\n","# Para o DataFrame de Acompanhamento\n","print(\"--- df_acompanhamento_final ---\")\n","df_acompanhamento_final.info()\n","print(\"\\nPrimeiras linhas:\")\n","print(df_acompanhamento_final.head())\n","print(\"\\n\")\n","\n","# Para o DataFrame de Pr√©-natal\n","print(\"--- df_prenatal_final ---\")\n","df_prenatal_final.info()\n","print(\"\\nPrimeiras linhas:\")\n","print(df_prenatal_final.head())\n","\n","# Importante citar que enquanto nos 2 primeiros co_indio_desidentificado √© um\n","# codigo para a crian√ßa, no de pre-natal √© um codigo para a m√£e, e n√£o est√£o\n","# relacionados diretamente"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_sz7C7d3GAmv"},"outputs":[],"source":["# 1.3. Consolida√ß√£o dos DataFrames\n","# Chaves de jun√ß√£o: identificador do indiv√≠duo e a data do atendimento.\n","chaves = ['co_indio_desidentificado', 'dt_atendimento']\n","\n","# Realizando a jun√ß√£o 'outer' para n√£o perder registros de nenhum dos lados.\n","df_consolidado = pd.merge(\n","    df_vigilancia_final,\n","    df_acompanhamento_final,\n","    on=chaves,\n","    how='outer',\n","    suffixes=('_vigilancia', '_acompanhamento') # Adiciona sufixos para colunas com mesmo nome (exceto as chaves)\n",")\n","\n","# Verificando o resultado\n","print(\"--- Informa√ß√µes do DataFrame Consolidado ---\")\n","df_consolidado.info()\n","\n","print(\"\\n--- Primeiras linhas do DataFrame Consolidado ---\")\n","print(df_consolidado.head())\n","\n","print(f\"\\nShape do df_vigilancia_final: {df_vigilancia_final.shape}\")\n","print(f\"Shape do df_acompanhamento_final: {df_acompanhamento_final.shape}\")\n","print(f\"Shape do df_consolidado: {df_consolidado.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"gzlXCCsOIKOs"},"source":["## 1.4. Engenharia de Vari√°veis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hJZPTw_UHMp5"},"outputs":[],"source":["# 1.4. Engenharia de Vari√°veis\n","\n","# Primeiro, vamos unificar as colunas de data de nascimento que foram duplicadas no merge.\n","# O m√©todo 'bfill' preenche os nulos de uma coluna com o valor da pr√≥xima coluna (no eixo 1).\n","df_consolidado['dt_nascimento'] = df_consolidado['dt_nascimento_vigilancia'].bfill(axis=0)\n","\n","# 1. Calcular a idade em anos\n","# A diferen√ßa entre as datas resulta em um 'Timedelta'. Dividimos pelo n√∫mero de dias em um ano.\n","# Usar 365.25 dias ajuda a contabilizar os anos bissextos de forma aproximada.\n","dias_no_ano = 365.25\n","df_consolidado['idade_anos'] = (df_consolidado['dt_atendimento'] - df_consolidado['dt_nascimento']).dt.days / dias_no_ano\n","\n","print(\"\\n--- Verificando a nova coluna 'idade_anos' ---\")\n","print(df_consolidado[['dt_nascimento', 'dt_atendimento', 'idade_anos']].head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"apolZF2DI_4n"},"outputs":[],"source":["import numpy as np\n","\n","# Unificar Colunas Duplicadas\n","print(\"Iniciando a unifica√ß√£o de colunas duplicadas...\")\n","\n","# Lista das colunas que foram duplicadas no merge e que queremos unificar\n","colunas_para_unificar = [\n","    'ano', 'dsei_gestao', 'co_dsei_gestao', 'cod_polo_base', 'ds_polo_base',\n","    'no_terra_indigena', 'co_municipio_ibge', 'no_municipio', 'sg_uf',\n","    'dt_nascimento', 'tp_sexo', 'mes_atend', 'ano_atend', 'co_profissional',\n","    'co_cbo_familia', 'ds_cbo_familia', 'co_ocupacao', 'ds_cbo_ocupacao',\n","    'nu_peso', 'nu_altura', 'idade_meses_atend'\n","]\n","\n","# Loop para unificar cada coluna\n","for col in colunas_para_unificar:\n","    col_vig = f'{col}_vigilancia'\n","    col_acomp = f'{col}_acompanhamento'\n","\n","    # Verifica se as colunas com sufixo existem no DataFrame\n","    if col_vig in df_consolidado.columns and col_acomp in df_consolidado.columns:\n","        # Usa combine_first para preencher NaNs de uma coluna com valores da outra\n","        df_consolidado[col] = df_consolidado[col_vig].combine_first(df_consolidado[col_acomp])\n","        # Remove as colunas antigas com sufixo\n","        df_consolidado.drop(columns=[col_vig, col_acomp], inplace=True)\n","        print(f\" -> Coluna '{col}' unificada.\")\n","\n","# Tratamento especial para colunas que s√≥ existem em um dos DFs originais\n","# Renomeando para um nome padr√£o sem sufixo\n","df_consolidado.rename(columns={\n","    'ds_peso_idade_vigilancia': 'ds_peso_idade',\n","    'ds_estatura_idade_vigilancia': 'ds_estatura_idade',\n","    'ds_imc_idade_vigilancia': 'ds_imc_idade',\n","    'tipo_aleitamento_vigilancia': 'tipo_aleitamento'\n","}, inplace=True)\n","print(\" -> Colunas de vigil√¢ncia renomeadas.\")\n","\n","\n","import numpy as np\n","\n","# Criar Vari√°vel Bin√°ria 'desnutricao' para RQ2\n","print(\"Corrigindo a cria√ß√£o da vari√°vel 'desnutricao'...\")\n","\n","# Lista CORRETA das categorias que indicam desnutri√ß√£o\n","categorias_desnutricao_correta = ['MUITO BAIXO PESO PARA A IDADE', 'BAIXO PESO PARA A IDADE']\n","\n","# Recria a coluna 'desnutricao' com a l√≥gica certa\n","# 1 se ds_peso_idade estiver na lista, 0 caso contr√°rio. np.nan se o dado for nulo.\n","df_consolidado['desnutricao'] = np.where(\n","    df_consolidado['ds_peso_idade'].isin(categorias_desnutricao_correta), 1,\n","    np.where(df_consolidado['ds_peso_idade'].notna(), 0, np.nan)\n",")\n","\n","print(\" -> Vari√°vel 'desnutricao' corrigida.\")\n","print(\"\\nNova verifica√ß√£o da coluna:\")\n","# Vamos usar o crosstab que √© ainda mais claro para verifica√ß√£o\n","print(pd.crosstab(df_consolidado['ds_peso_idade'], df_consolidado['desnutricao'], dropna=False))\n","\n","# Limpeza e Verifica√ß√£o\n","print(\"\\nDataFrame final ap√≥s engenharia de vari√°veis:\")\n","df_consolidado.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XnpIIXSARU6k"},"outputs":[],"source":["\n","# 1. Salvar o DataFrame principal (das crian√ßas)\n","print(\"Salvando o DataFrame das crian√ßas (vigil√¢ncia + acompanhamento)...\")\n","df_consolidado.to_csv(folder_path + 'projeto_icd/data_base/dados_consolidados_criancas.csv', index=False)\n","print(\"-> Arquivo 'dados_consolidados_criancas.csv' salvo com sucesso!\")\n","\n","# 2. Salvar o DataFrame do pr√©-natal\n","print(\"\\nSalvando o DataFrame do pr√©-natal...\")\n","df_prenatal_final.to_csv(folder_path + 'projeto_icd/data_base/dados_consolidados_prenatal.csv', index=False)\n","print(\"-> Arquivo 'dados_consolidados_prenatal.csv' salvo com sucesso!\")"]},{"cell_type":"markdown","metadata":{"id":"tAUcPvemwrSy"},"source":["# üòú Parte 2"]},{"cell_type":"markdown","metadata":{"id":"-PY-XEcEwrTM"},"source":["## 2.1. Perguntas Explorat√≥rias Adicionais"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xTn2EUiNwrTN"},"outputs":[],"source":["\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Configura√ß√µes de visualiza√ß√£o para os gr√°ficos\n","sns.set_style(\"whitegrid\")\n","plt.rcParams['figure.figsize'] = (10, 6)\n","plt.rcParams['font.size'] = 12"]},{"cell_type":"markdown","metadata":{"id":"zSF-OnJqwrTN"},"source":["Qual a preval√™ncia dos principais diagn√≥sticos nutricionais?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m9JHrSJDAuXq"},"outputs":[],"source":["\n","from matplotlib.ticker import FuncFormatter\n","\n","#Fun√ß√£o para formatar n√∫meros grandes\n","def human_readable_formatter(x, pos):\n","    \"\"\"\n","    Formata n√∫meros grandes em uma string leg√≠vel (ex: 1.5M, 250K).\n","    \"\"\"\n","    if x >= 1_000_000:\n","        # Formata como '1.0 M', '2.5 M', etc.\n","        return f'{x / 1_000_000:.1f} M'\n","    if x >= 1_000:\n","        # Formata como '250 K', '500 K' (sem casas decimais)\n","        return f'{x / 1_000:.0f} K'\n","    # Retorna o n√∫mero como inteiro se for menor que 1000\n","    return f'{x:.0f}'\n","\n","# Criar o objeto formatador\n","formatter = FuncFormatter(human_readable_formatter)\n","\n","# --- Plotagem ---\n","print(\"Preval√™ncia dos Diagn√≥sticos Nutricionais\")\n","\n","\n","\n","\n","fig, axes = plt.subplots(1, 2, figsize=(20, 7))\n","fig.suptitle('Preval√™ncia dos Principais Diagn√≥sticos Nutricionais (N¬∫ Absoluto)', fontsize=16)\n","\n","#Gr√°fico 1: Peso para Idade\n","sns.countplot(data=df_criancas, y='ds_peso_idade', ax=axes[0],\n","              order=df_criancas['ds_peso_idade'].value_counts().index, palette='Blues_d')\n","axes[0].set_title('Peso para Idade')\n","axes[0].set_xlabel('Contagem (N¬∫ de Atendimentos)')\n","axes[0].set_ylabel('Diagn√≥stico')\n","# Aplicar o formatador ao eixo X\n","axes[0].xaxis.set_major_formatter(formatter)\n","\n","#Gr√°fico 2: Estatura para Idade\n","sns.countplot(data=df_criancas, y='ds_estatura_idade', ax=axes[1],\n","              order=df_criancas['ds_estatura_idade'].value_counts().index, palette='Greens_d')\n","axes[1].set_title('Estatura para Idade')\n","axes[1].set_xlabel('Contagem (N¬∫ de Atendimentos)')\n","axes[1].set_ylabel('') # Oculta o label y\n","# Aplicar o formatador ao eixo X\n","axes[1].xaxis.set_major_formatter(formatter)\n","\n","#Adicionar R√≥tulos de Dados\n","def add_labels_countplot(ax):\n","    max_val = max(p.get_width() for p in ax.patches)\n","    lim_buffer = max_val * 0.02 # Pequeno espa√ßo da barra\n","\n","    for p in ax.patches:\n","        width = p.get_width()\n","        # Usar a mesma fun√ß√£o de formata√ß√£o para o r√≥tulo\n","        label_text = human_readable_formatter(width, None)\n","\n","        ax.text(width + lim_buffer, # Posi√ß√£o X\n","                p.get_y() + p.get_height() / 2., # Posi√ß√£o Y\n","                label_text,\n","                ha='left',\n","                va='center',\n","                fontsize=10)\n","\n","add_labels_countplot(axes[0])\n","add_labels_countplot(axes[1])\n","\n","# Ajustar os limites do eixo X para dar espa√ßo aos r√≥tulos\n","try:\n","    max_peso = df_criancas['ds_peso_idade'].value_counts().max()\n","    max_estatura = df_criancas['ds_estatura_idade'].value_counts().max()\n","    common_xlim = max(max_peso, max_estatura) * 1.15\n","    axes[0].set_xlim(0, common_xlim)\n","    axes[1].set_xlim(0, common_xlim)\n","except Exception:\n","    pass\n","\n","plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Ajusta o layout\n","plt.savefig(\"prevalencia_diagnosticos_formatado.png\") # Salva a imagem\n","plt.show()\n","\n","print(\"\\nValores Percentuais (Peso para Idade):\")\n","print((df_criancas['ds_peso_idade'].value_counts(normalize=True, dropna=False) * 100).round(2))\n","\n","print(\"\\nValores Percentuais (Estatura para Idade):\")\n","print((df_criancas['ds_estatura_idade'].value_counts(normalize=True, dropna=False) * 100).round(2))"]},{"cell_type":"markdown","metadata":{"id":"J4JMOT4PwrTO"},"source":["sugest√£o: encontrar os dados da popula√ß√£o brasileira para fazer um teste de hip√≥tese"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"krbK1ACJDrRL"},"outputs":[],"source":["\n","print(\"\\n--- 2. Distribui√ß√£o de Idades e Sexo ---\")\n","\n","# Criar DF filtrado\n","df_plotar_demo = df_criancas[df_criancas['idade_anos'] >= 0].copy()\n","\n","#    Usamos np.floor() para \"arredondar para baixo\" (ex: 1.9 anos vira 1)\n","df_plotar_demo['idade_anos_completos'] = df_plotar_demo['idade_anos'].apply(np.floor).astype(int)\n","\n","\n","\n","# Criar uma figura com 2 subplots\n","fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n","# T√≠tulo atualizado para refletir os dados limpos\n","fig.suptitle('Distribui√ß√£o Demogr√°fica da Amostra (Idades >= 0)', fontsize=16)\n","\n","# Gr√°fico 1: Contagem de Idades\n","#    Usamos sns.countplot para ter uma barra discreta para cada ano\n","sns.countplot(\n","    data=df_plotar_demo,\n","    x='idade_anos_completos',\n","    ax=axes[0],\n","    palette='Blues_d'\n",")\n","axes[0].set_title('Distribui√ß√£o de Idades (em anos completos)')\n","axes[0].set_xlabel('Idade (anos completos)')\n","axes[0].set_ylabel('Frequ√™ncia')\n","axes[0].set_xlim(left=-0.5)\n","\n","# Gr√°fico 2: Contagem de Sexo\n","try:\n","    order_sexo = df_plotar_demo['tp_sexo'].value_counts().index\n","except KeyError:\n","    order_sexo = None\n","\n","sns.countplot(\n","    data=df_plotar_demo,\n","    x='tp_sexo',\n","    ax=axes[1],\n","    order=order_sexo\n",")\n","axes[1].set_title('Distribui√ß√£o por Sexo (Amostra com Idade >= 0)')\n","axes[1].set_xlabel('Sexo')\n","axes[1].set_ylabel('Contagem')\n","\n","plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","plt.savefig(\"distribuicao_demografica_corrigida.png\")\n","\n","# --- 4. Imprimir estat√≠sticas (Usando os dados limpos) ---\n","\n","print(\"\\nEstat√≠sticas da Idade (APENAS anos >= 0):\")\n","# Descreve a coluna de inteiros que foi plotada\n","print(df_plotar_demo['idade_anos_completos'].describe())\n","\n","print(\"\\nContagem por Sexo (APENAS amostra com Idade >= 0):\")\n","# Conta o sexo no DataFrame filtrado\n","try:\n","    print(df_plotar_demo['tp_sexo'].value_counts(dropna=False))\n","except KeyError:\n","    print(\"Coluna 'tp_sexo' n√£o encontrada nos dados de exemplo.\")"]},{"cell_type":"markdown","metadata":{"id":"u17yylU1wrTO"},"source":["Como se distribuem as idades e o sexo na amostra?"]},{"cell_type":"markdown","metadata":{"id":"6RMF_4GXwrTO"},"source":["Quais s√£o os tipos de aleitamento mais comuns?"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","print(\" Tipos de Aleitamento Mais Comuns (Filtro: Crian√ßas de 0 a 2 anos) ---\")\n","\n","\n","try:\n","    df_aleitamento_0a1 = df_criancas[\n","        (df_criancas['idade_anos'] >= 0) &\n","        (df_criancas['idade_anos'] < 2)\n","    ].copy()\n","\n","    print(f\"\\nAnalisando {len(df_aleitamento_0a1):,} atendimentos de crian√ßas no primeiro ano de vida (Idade >= 0 e < 1).\")\n","\n","    #Plot\n","    plt.figure(figsize=(12, 7))\n","\n","    sns.countplot(\n","        data=df_aleitamento_0a1,\n","        y='tipo_aleitamento',\n","        order=df_aleitamento_0a1['tipo_aleitamento'].value_counts().index\n","    )\n","\n","    plt.title('Frequ√™ncia dos Tipos de Aleitamento (Crian√ßas de 0 a 2 anos)')\n","    plt.xlabel('Contagem (N¬∫ de Atendimentos)')\n","    plt.ylabel('Tipo de Aleitamento')\n","\n","    plt.savefig(\"tipos_aleitamento_0a1_ano.png\")\n","    print(\"Gr√°fico 'tipos_aleitamento_0a1_ano.png' salvo.\")\n","    plt.show()\n","\n","    print(\"\\nFrequ√™ncia por Tipo de Aleitamento (em %) - (Crian√ßas de 0 a 2 anos):\")\n","    print((df_aleitamento_0a1['tipo_aleitamento'].value_counts(normalize=True, dropna=False) * 100).round(2))\n","\n","except KeyError as e:\n","    print(f\"\\nErro: Coluna {e} n√£o encontrada. N√£o foi poss√≠vel executar a filtragem.\")\n","except NameError:\n","    print(\"\\nErro: DataFrame 'df_criancas' n√£o encontrado. Carregue os dados primeiro.\")\n","except Exception as e:\n","    print(f\"\\nOcorreu um erro inesperado: {e}\")"],"metadata":{"id":"xFGC1gxC5tfB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kLeZVxTpwrTO"},"source":["Quais os profissionais de sa√∫de (ds_cbo_familia) que mais realizam atendimentos?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rIeK--gYwrTP"},"outputs":[],"source":["print(\"\\n--- 4. Profissionais de Sa√∫de que Mais Realizam Atendimentos ---\")\n","\n","profissionais_conhecidos = df_criancas[df_criancas['ds_cbo_familia'] != 'DESCONHECIDO']\n","\n","# Pegar o Top 10 profissionais\n","top_10_profissionais = profissionais_conhecidos['ds_cbo_familia'].value_counts().nlargest(10)\n","\n","plt.figure(figsize=(12, 8))\n","sns.barplot(x=top_10_profissionais.values, y=top_10_profissionais.index, palette='viridis')\n","plt.title('Top 10 Profissionais por N¬∫ de Atendimentos (Fam√≠lia CBO)')\n","plt.xlabel('N√∫mero de Atendimentos')\n","plt.ylabel('Fam√≠lia CBO (Profissional)')\n","plt.show()\n","\n","# Imprimir valores\n","print(\"\\nTop 10 Profissionais (ds_cbo_familia), excluindo 'DESCONHECIDO':\")\n","print(top_10_profissionais)"]},{"cell_type":"markdown","metadata":{"id":"43JyiysJwrTP"},"source":["## 2.2. An√°lise Univariada"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8m_qdTn5wrTP"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Configura√ß√µes de visualiza√ß√£o para os gr√°ficos\n","sns.set_style(\"whitegrid\")\n","plt.rcParams['figure.figsize'] = (12, 7) # Um bom tamanho padr√£o\n","plt.rcParams['font.size'] = 12\n","\n","print(\"Iniciando a An√°lise Univariada (Tarefa 2.2)...\")\n","print(\"=\"*50 + \"\\n\")\n","\n","#An√°lise de Vari√°veis Num√©ricas\n","print(\"--- 1. An√°lise de Vari√°veis Num√©ricas ---\")\n","\n","# 1.1. Lista das nossas vari√°veis num√©ricas de interesse\n","numerical_vars = ['nu_peso', 'nu_altura', 'idade_meses_atend']\n","\n","# 1.2. Estat√≠sticas Descritivas\n","print(\"Estat√≠sticas Descritivas (Num√©ricas):\")\n","# .describe() nos d√° a contagem (count), m√©dia (mean), desvio padr√£o (std),\n","# m√≠nimo (min), quartis (25%, 50%, 75%) e m√°ximo (max).\n","# Note que a 'count' s√≥ considera valores n√£o-nulos.\n","estatisticas_num = df_criancas[numerical_vars].describe()\n","# display(estatisticas_num) # Use display() se estiver no Jupyter/Colab\n","print(estatisticas_num)\n","print(\"\\n\")\n","\n","# 1.3. Gerando Gr√°ficos (Histograma e Boxplot)\n","print(\"Gerando gr√°ficos para vari√°veis num√©ricas...\")\n","\n","for var in numerical_vars:\n","    print(f\"Analisando: {var}\")\n","\n","    # Precisamos remover os valores nulos (NaN) para plotar\n","    # O dropna() aqui s√≥ afeta 'data_to_plot', n√£o o seu df_criancas original\n","    data_to_plot = df_criancas[var].dropna()\n","\n","    # Criar uma figura com 2 subplots (um ao lado do outro)\n","    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n","\n","    # Define um t√≠tulo principal para os dois gr√°ficos\n","    fig.suptitle(f'An√°lise Univariada de: {var}', fontsize=16)\n","\n","    # Gr√°fico 1: Histograma (para ver a distribui√ß√£o)\n","    sns.histplot(data_to_plot, kde=True, ax=axes[0])\n","    axes[0].set_title('Histograma (Distribui√ß√£o)')\n","    axes[0].set_xlabel(var)\n","    axes[0].set_ylabel('Frequ√™ncia')\n","\n","    # Gr√°fico 2: Boxplot (para ver outliers)\n","    sns.boxplot(x=data_to_plot, ax=axes[1])\n","    axes[1].set_title('Boxplot (Mediana e Outliers)')\n","    axes[1].set_xlabel(var)\n","\n","    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Ajusta layout para o t√≠tulo\n","    plt.show()\n","\n","print(\"\\n\" + \"=\"*50 + \"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"n-xqYboBwrTP"},"source":["\n","### An√°lise da Vari√°vel: Peso (`nu_peso`)\n","\n","A distribui√ß√£o do peso (`nu_peso`) apresenta uma **forte assimetria √† direita** (right-skew). O histograma revela uma grande concentra√ß√£o de registros com um pico de frequ√™ncia em torno de 10-12 kg, com um pico menor para pesos muito baixos (provavelmente rec√©m-nascidos). O boxplot confirma essa an√°lise de forma contundente: enquanto a \"caixa\" (o intervalo interquartil, ou 50% central dos dados) est√° compactada em valores baixos (aprox. 8-14 kg), o gr√°fico √© dominado por uma **longa cauda de outliers** √† direita. A presen√ßa de milhares de registros acima de 20 kg (chegando at√© ~40 kg) \"estica\" o eixo do boxplot, comprimindo a visualiza√ß√£o da maioria. Isso sugere fortemente a presen√ßa de um subgrupo significativo de crian√ßas com sobrepeso/obesidade.\n","\n","### An√°lise da Vari√°vel: Idade em Meses (`idade_meses_atend`)\n","\n","Diferente do peso, a vari√°vel `idade_meses_atend` apresenta uma **distribui√ß√£o quase uniforme**, o que √© um excelente sinal para a an√°lise. O histograma mostra que h√° um n√∫mero relativamente consistente de atendimentos em todas as faixas et√°rias mensais, de 0 a 60 meses (5 anos). H√° um pico not√°vel de atendimentos em idades muito precoces (pr√≥ximo de 0 meses), e um decl√≠nio natural ap√≥s os 50 meses, indicando o limite de idade (5 anos) deste conjunto de dados. O boxplot reflete perfeitamente essa uniformidade: a \"caixa\" √© larga e centrada, e os \"bigodes\" (whiskers) cobrem quase todo o intervalo, com **praticamente nenhuma presen√ßa de outliers**. Isso indica que os dados de idade s√£o bem distribu√≠dos e \"limpos\", sem valores at√≠picos que poderiam distorcer a an√°lise.\n","\n","### An√°lise da Vari√°vel: Altura (`nu_altura`)\n","\n","A distribui√ß√£o da altura (`nu_altura`) √© particularmente interessante. O histograma sugere uma **distribui√ß√£o bimodal** (com dois picos) ou, pelo menos, multimodal. Nota-se uma grande concentra√ß√£o de crian√ßas em torno de 75-80 cm e outra em torno de 90-100 cm, com um \"vale\" (queda na frequ√™ncia) entre elas. Isso √© comum em dados que agregam diferentes faixas et√°rias; os picos podem simplesmente representar os grupos de crian√ßas mais novas (ex: 1-2 anos) e mais velhas (ex: 3-4 anos). O boxplot mostra que a mediana (a linha central) est√° em torno de 85 cm, que √© exatamente o \"vale\" entre os dois picos. Assim como no peso, vemos tamb√©m uma cauda de outliers √† direita (alturas acima de 120 cm), embora em menor quantidade, que podem ser erros de digita√ß√£o (ex: 140 cm em vez de 104 cm) ou crian√ßas mais velhas fora da curva."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_CMxgt8bwrTP"},"outputs":[],"source":["print(\"An√°lise de Vari√°veis Categ√≥ricas\")\n","\n","# 2.1. Lista das nossas vari√°veis categ√≥ricas de interesse\n","categorical_vars = ['dsei_gestao', 'tipo_aleitamento']\n","\n","# 2.2. Gerando Gr√°ficos (Gr√°fico de Barras)\n","print(\"Gerando gr√°ficos para vari√°veis categ√≥ricas...\")\n","\n","for var in categorical_vars:\n","    print(f\"Analisando: {var}\")\n","\n","    # 2.3. Contar as frequ√™ncias de cada categoria\n","    # .value_counts() j√° ignora os valores nulos (NaN) por padr√£o\n","    counts = df_criancas[var].value_counts()\n","\n","    # Preparar a figura\n","    plt.figure(figsize=(12, 8))\n","\n","    # 2.4. Plotar o gr√°fico de barras\n","    # se tivermos muitas categorias (ex: DSEIs), pois fica mais f√°cil de ler.\n","\n","    if len(counts) > 10:\n","        # Gr√°fico Horizontal (barh) - √≥timo para muitas categorias\n","        # Usamos .sort_values(ascending=True) para o maior ficar no topo\n","        counts.sort_values(ascending=True).plot(kind='barh')\n","        plt.title(f'Frequ√™ncia de: {var} (Top {len(counts)})')\n","        plt.xlabel('Contagem (N¬∫ de Registros)')\n","        plt.ylabel(var)\n","    else:\n","        # Gr√°fico Vertical (bar) - bom para poucas categorias\n","        counts.sort_values(ascending=False).plot(kind='bar')\n","        plt.title(f'Frequ√™ncia de: {var}')\n","        plt.ylabel('Contagem (N¬∫ de Registros)')\n","        plt.xlabel(var)\n","        plt.xticks(rotation=45, ha='right') # Gira os r√≥tulos para n√£o sobrepor\n","\n","    plt.tight_layout() # Ajusta o layout\n","    plt.show()\n","\n","    print(f\"Contagens para '{var}':\")\n","    print(counts)\n","    print(\"\\n\")\n","\n","print(\"=\"*50)\n","print(\"An√°lise Univariada conclu√≠da!\")"]},{"cell_type":"markdown","metadata":{"id":"cwTxllqbwrTQ"},"source":["## 2.3. RQ2: Distribui√ß√£o Geogr√°fica dos Indicadores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aIkB5IjSwrTQ"},"outputs":[],"source":["df_criancas['dsei_gestao'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JPDDWFIUwrTQ"},"outputs":[],"source":["df_criancas['ds_peso_idade'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NnjZjQyswrTQ"},"outputs":[],"source":["df_criancas['ds_estatura_idade'].unique()"]},{"cell_type":"markdown","metadata":{"id":"oCZZlZlEwrTQ"},"source":["Os valores do DSEI_gest√£o parecem n√£o ser padronizados, apresentando diferentes formatos de representta√ß√µes geogr√°ficas: alguns s√£o munic√≠pios, outros regi√µes de rios e etc. Assim, para visualizar melhor a distribui√ß√£o das categorias, podemos utilizar o munic√≠pio!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LeAlLaPGwrTR"},"outputs":[],"source":["df_criancas['co_municipio_ibge'].head()"]},{"cell_type":"markdown","metadata":{"id":"Bf72OXmhwrTR"},"source":["### Problemas nutricionais (peso para idade)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hb6A9HlawrTR"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Configura√ß√µes de visualiza√ß√£o para os gr√°ficos\n","sns.set_style(\"whitegrid\")\n","plt.rcParams['figure.figsize'] = (10, 6)\n","plt.rcParams['font.size'] = 12\n","\n","print(\"\\n--- 1. Preval√™ncia de Peso para Idade por Munic√≠pio (excluindo NaNs e 'N√ÉO SE APLICA') ---\")\n","\n","# Filtrar o DataFrame para remover NaNs e 'N√ÉO SE APLICA' da coluna 'ds_peso_idade'\n","df_peso_idade_filtrado = df_criancas[\n","    (df_criancas['ds_peso_idade'].notna()) &\n","    (df_criancas['ds_peso_idade'] != 'N√ÉO SE APLICA')\n","].copy() # Usar .copy() para evitar SettingWithCopyWarning\n","\n","# Agrupar por munic√≠pio e contar os valores de ds_peso_idade\n","prevalencia_por_municipio = df_peso_idade_filtrado.groupby('no_municipio')['ds_peso_idade'].value_counts().unstack(fill_value=0)\n","\n","# Calcular as porcentagens dentro de cada munic√≠pio\n","prevalencia_por_municipio_percentual = prevalencia_por_municipio.apply(lambda x: x / x.sum() * 100, axis=1)\n","\n","print(\"\\nContagem por Munic√≠pio e Diagn√≥stico de Peso para Idade:\")\n","display(prevalencia_por_municipio.head()) # Exibir as primeiras linhas\n","\n","print(\"\\nPreval√™ncia Percentual por Munic√≠pio e Diagn√≥stico de Peso para Idade:\")\n","display(prevalencia_por_municipio_percentual.head()) # Exibir as primeiras linhas\n","\n","# Opcional: Visualizar a distribui√ß√£o em alguns munic√≠pios (exemplo com os 5 primeiros)\n","top_municipios = prevalencia_por_municipio.sum(axis=1).nlargest(5).index\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1O_BDUHXwrTR"},"outputs":[],"source":["import geopandas as gpd\n","import geobr\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Configura√ß√µes de visualiza√ß√£o\n","sns.set_style(\"whitegrid\")\n","plt.rcParams['figure.figsize'] = (12, 10) # Tamanho maior para mapas\n","plt.rcParams['font.size'] = 12\n","\n","print(\"--- 1. Preparando os dados de Nutri√ß√£o ---\")\n","\n","# 1.1. Filtrar o DataFrame (como voc√™ j√° fez)\n","# Exclui NaNs e 'N√ÉO SE APLICA'\n","df_peso_idade_filtrado = df_criancas[\n","    (df_criancas['ds_peso_idade'].notna()) &\n","    (df_criancas['ds_peso_idade'] != 'N√ÉO SE APLICA')\n","].copy()\n","\n","# 1.2. Calcular as contagens por munic√≠pio (como voc√™ j√° fez)\n","prevalencia_por_municipio = df_peso_idade_filtrado.groupby('no_municipio')['ds_peso_idade'].value_counts().unstack(fill_value=0)\n","\n","# 1.3. ACHAR A CATEGORIA MAIS FREQUENTE (O PONTO CHAVE DA SUA PERGUNTA)\n","# .idxmax(axis=1) retorna o nome da coluna (categoria) que tem o maior valor em cada linha (munic√≠pio)\n","df_frequente = prevalencia_por_municipio.idxmax(axis=1).to_frame(name='categoria_mais_frequente')\n","\n","print(\"Categoria mais frequente por munic√≠pio:\")\n","# display(df_frequente.head()) # Use display no Jupyter\n","print(df_frequente.head())\n","print(\"\\n\")\n","\n","# 1.4. Precisamos do 'co_municipio_ibge' para juntar com o mapa.\n","# Vamos criar um \"mapa\" de 'no_municipio' para 'co_municipio_ibge'\n","# Usamos drop_duplicates para ter apenas uma linha por munic√≠pio\n","mapa_municipio_ibge = df_peso_idade_filtrado.drop_duplicates(subset=['no_municipio'])[['no_municipio', 'co_municipio_ibge']]\n","\n","\n","# 1.5. Juntar a categoria mais frequente com o c√≥digo IBGE\n","# 'df_frequente' √© indexado por 'no_municipio'\n","dados_para_mapa = df_frequente.merge(\n","    mapa_municipio_ibge,\n","    left_index=True,       # Chave da esquerda (df_frequente) √© o √≠ndice\n","    right_on='no_municipio' # Chave da direita √© a coluna 'no_municipio'\n",")\n","\n","print(\"Dados prontos para o merge com o mapa:\")\n","# display(dados_para_mapa.head()) # Use display no Jupyter\n","print(dados_para_mapa.head())\n","print(\"\\n\")\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0PWnAt3EwrTR"},"source":["Todos os munic√≠pios parecem ter como categoria mais frequente  PESO ADEQUADO PARA A IDADE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3UD9ULSZwrTR"},"outputs":[],"source":["print(\"--- 2. Testando Varia√ß√£o da Categoria Mais Frequente ---\")\n","\n","# Verifica√ß√£o 1: Usar value_counts() para ver a distribui√ß√£o\n","# Isso mostra exatamente quantas cidades caem em cada categoria principal.\n","print(\"Distribui√ß√£o das categorias mais frequentes:\")\n","contagem_categorias = dados_para_mapa['categoria_mais_frequente'].value_counts()\n","\n","# display(contagem_categorias) # Use display no Jupyter\n","print(contagem_categorias)\n","print(\"\\n\")\n","\n","\n","# Verifica√ß√£o 2: Teste l√≥gico com nunique()\n","# .nunique() retorna apenas o N√öMERO de itens √∫nicos.\n","num_categorias_unicas = dados_para_mapa['categoria_mais_frequente'].nunique()\n","\n","print(f\"Total de munic√≠pios analisados: {len(dados_para_mapa)}\")\n","print(f\"N√∫mero de categorias √∫nicas encontradas: {num_categorias_unicas}\")\n","print(\"\\n\")\n","\n","# Resultado final do teste\n","if num_categorias_unicas == 1:\n","    # .index[0] pega o nome da √∫nica categoria encontrada\n","    categoria_unica = contagem_categorias.index[0]\n","    print(f\"RESULTADO DO TESTE: SIM, todos os {len(dados_para_mapa)} munic√≠pios t√™m o MESMO valor.\")\n","    print(f\"A √∫nica categoria mais frequente √©: '{categoria_unica}'\")\n","elif num_categorias_unicas > 1:\n","    print(f\"RESULTADO DO TESTE: N√ÉO, os munic√≠pios t√™m valores diferentes.\")\n","    print(f\"Foram encontrados {num_categorias_unicas} valores distintos (listados acima).\")\n","    print(\"Portanto, o mapa coropl√©tico mostrar√° varia√ß√£o de cores.\")\n","else:\n","    # Isso s√≥ aconteceria se 'dados_para_mapa' estivesse vazio\n","    print(\"RESULTADO DO TESTE: Nenhum dado encontrado para testar.\")\n","\n","print(\"\\n\" + \"=\"*50)"]},{"cell_type":"markdown","metadata":{"id":"-K9T-hMGwrTS"},"source":["\n","O teste que fizemos no passo anterior procura a categoria mais frequente (a moda) em cada munic√≠pio. O resultado de 'PESO ADEQUADO PARA A IDADE' ser o vencedor em todos os lugares significa simplesmente que, em todos os munic√≠pios, a maioria das crian√ßas (ou pelo menos o maior grupo individual) se enquadra na faixa de normalidade.\n","\n","Isso √© um sinal positivo, mas torna o mapa (o de \"categoria mais frequente\") pouco √∫til, pois ele seria pintado com uma cor s√≥.\n","\n","Ent√£o, a pergunta anal√≠tica mais rica agora √©: \"Ok, se ignorarmos as crian√ßas com peso adequado, qual √© o problema nutricional mais comum em cada munic√≠pio?\"\n","\n","Estamos essencialmente \"dando zoom\" nos dados, filtrando a normalidade para focar nos desvios:\n","\n","Desnutri√ß√£o ('BAIXO PESO PARA A IDADE', 'MUITO BAIXO PESO PARA A IDADE')\n","\n","Sobrepeso ('PESO ELEVADO PARA A IDADE')\n","\n","Ao fazer isso, conseguiremos criar um mapa que mostra clusters geogr√°ficos: \"Estes munic√≠pios t√™m a desnutri√ß√£o como principal problema\" vs. \"Aqueles munic√≠pios t√™m o sobrepeso como principal problema\".\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dlMgByyswrTS"},"outputs":[],"source":["import geopandas as gpd\n","import geobr\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import matplotlib.colors\n","\n","# Configura√ß√µes de visualiza√ß√£o\n","sns.set_style(\"whitegrid\")\n","plt.rcParams['figure.figsize'] = (12, 10) # Tamanho maior para mapas\n","plt.rcParams['font.size'] = 12\n","\n","print(\"--- 1. Revisitando Contagens e Definindo Categorias ---\")\n","\n","\n","# 1.1. Definir as colunas que representam \"problemas\"\n","# ATEN√á√ÉO: Verifique se os nomes est√£o EXATAMENTE iguais aos do seu DataFrame\n","categorias_problema = [\n","    'PESO ELEVADO PARA A IDADE',\n","    'BAIXO PESO PARA A IDADE',\n","    'MUITO BAIXO PESO PARA A IDADE'\n","]\n","\n","# 1.2. Filtrar o DataFrame de preval√™ncia para conter APENAS as categorias de problema\n","# Usamos .reindex() para garantir que colunas que n√£o existam em algum munic√≠pio\n","# sejam preenchidas com 0, evitando erros.\n","colunas_presentes = [col for col in prevalencia_por_municipio.columns if col in categorias_problema]\n","df_problemas = prevalencia_por_municipio[colunas_presentes]\n","\n","print(\"Contagem apenas das categorias de 'Problema' (amostra):\")\n","\n","print(df_problemas.head())\n","print(\"\\n\")\n","\n","# 1.3. ACHAR O 'PROBLEMA' MAIS FREQUENTE\n","# Aplicamos o idxmax neste DataFrame filtrado\n","df_frequente_problema = df_problemas.idxmax(axis=1).to_frame(name='problema_mais_frequente')\n","\n","print(\"Problema nutricional mais frequente por munic√≠pio (amostra):\")\n","\n","print(df_frequente_problema.head())\n","print(\"\\n\")\n","\n","# 1.4. Juntar o 'problema mais frequente' com o c√≥digo IBGE\n","dados_para_mapa = df_frequente_problema.merge(\n","    mapa_municipio_ibge,\n","    left_index=True,\n","    right_on='no_municipio'\n",")\n","\n","print(\"Dados finais prontos para o merge com o mapa:\")\n","# display(dados_para_mapa.head()) # Use display no Jupyter\n","print(dados_para_mapa.head())\n","print(\"\\n\")\n","\n","\n","print(\"--- 2. Carregando Dados Geogr√°ficos (Shapefiles) ---\")\n","try:\n","    gdf_municipios = geobr.read_municipality(year=2020)\n","    print(\"Shapefile dos munic√≠pios do Brasil carregado com sucesso.\")\n","\n","    # 2.1. Ajuste da chave de 7 para 6 d√≠gitos\n","    gdf_municipios['co_ibge_6dig'] = gdf_municipios['code_muni'].astype(str).str[:6].astype(int)\n","    print(\"Coluna 'co_ibge_6dig' criada para o merge.\")\n","    print(\"\\n\")\n","\n","    print(\"--- 3. Unindo seus Dados ao Mapa (Merge) ---\")\n","\n","    dados_para_mapa['co_municipio_ibge'] = dados_para_mapa['co_municipio_ibge'].astype(str)\n","\n","    dados_para_mapa['co_municipio_ibge_numeric'] = pd.to_numeric(dados_para_mapa['co_municipio_ibge'], errors='coerce')\n","\n","\n","    nan_values_after_coerce = dados_para_mapa[dados_para_mapa['co_municipio_ibge_numeric'].isna()]\n","    if not nan_values_after_coerce.empty:\n","        print(f\"Found {len(nan_values_after_coerce)} rows with non-numeric 'co_municipio_ibge' after coercing to NaN.\")\n","        print(\"Original non-numeric values:\")\n","        print(nan_values_after_coerce['co_municipio_ibge'].unique())\n","\n","        dados_para_mapa.dropna(subset=['co_municipio_ibge_numeric'], inplace=True)\n","        print(\"Dropped rows with non-numeric 'co_municipio_ibge'.\")\n","\n","        dados_para_mapa.drop(columns=['co_municipio_ibge'], inplace=True)\n","\n","        dados_para_mapa.rename(columns={'co_municipio_ibge_numeric': 'co_municipio_ibge'}, inplace=True)\n","\n","    else:\n","        print(\"No non-numeric values found in 'co_municipio_ibge' after coercing to NaN.\")\n","\n","        dados_para_mapa.drop(columns=['co_municipio_ibge'], inplace=True)\n","        dados_para_mapa.rename(columns={'co_municipio_ibge_numeric': 'co_municipio_ibge'}, inplace=True)\n","\n","    dados_para_mapa['co_municipio_ibge'] = dados_para_mapa['co_municipio_ibge'].astype(int)\n","    print(f\"Dtype of 'co_municipio_ibge' in dados_para_mapa after converting to int: {dados_para_mapa['co_municipio_ibge'].dtype}\")\n","    print(f\"Dtype of 'co_ibge_6dig' in gdf_municipios: {gdf_municipios['co_ibge_6dig'].dtype}\")\n","\n","\n","    mapa_final = gdf_municipios.merge(\n","        dados_para_mapa,\n","        left_on='co_ibge_6dig',\n","        right_on='co_municipio_ibge'\n","    )\n","\n","    print(f\"Merge conclu√≠do. Temos {len(mapa_final)} munic√≠pios com dados.\")\n","\n","    if mapa_final.empty:\n","        print(\"!! ERRO: O merge n√£o encontrou munic√≠pios em comum. !!\")\n","    else:\n","        print(\"\\n--- 4. Plotando o Mapa Coropl√©tico ---\")\n","\n","        # 4.1. Definir um mapa de cores para os PROBLEMAS\n","        color_map = {\n","            'MUITO BAIXO PESO PARA A IDADE': '#b2182b', # Vermelho Escuro\n","            'BAIXO PESO PARA A IDADE': '#ef8a62',     # Laranja/Vermelho Claro\n","            'PESO ELEVADO PARA A IDADE': '#4393c3'      # Azul\n","        }\n","\n","        categorias_presentes_ordenadas = sorted(\n","            mapa_final['problema_mais_frequente'].dropna().unique()\n","        )\n","\n","        print(f\"Ordem das categorias que o Geopandas vai usar: {categorias_presentes_ordenadas}\")\n","\n","        # Segundo, criamos a LISTA de cores usando essa ordem alfab√©tica\n","        lista_de_cores_ordenadas = [\n","            color_map[categoria] for categoria in categorias_presentes_ordenadas\n","        ]\n","\n","        print(f\"Lista de cores na ordem correta: {lista_de_cores_ordenadas}\")\n","\n","        # Terceiro, criamos o ListedColormap\n","        cmap = matplotlib.colors.ListedColormap(lista_de_cores_ordenadas)\n","        fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n","\n","\n","        gdf_municipios.plot(ax=ax, color='lightgray', edgecolor='black', linewidth=0.1)\n","\n","        mapa_final.plot(\n","            column='problema_mais_frequente', # Coluna que define as cores\n","            categorical=True,                 # Essencial para categorias\n","            cmap=cmap,                        # Use the ListedColormap\n","            legend=True,\n","            legend_kwds={\n","                'title': 'Principal Problema Nutricional\\n(Excluindo \"Peso Adequado\")',\n","                'bbox_to_anchor': (1.05, 1),\n","                'loc': 'upper left'\n","            },\n","            ax=ax,\n","            edgecolor='black',\n","            linewidth=0.1\n","        )\n","\n","\n","        ax.set_title('Principal Problema Nutricional (Peso/Idade) por Munic√≠pio', fontsize=16)\n","        ax.axis('off')\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","except Exception as e:\n","    print(f\"Ocorreu um erro durante o processo de gera√ß√£o do mapa: {e}\")\n","    print(\"Verifique se as bibliotecas 'geopandas' e 'geobr' est√£o instaladas.\")"]},{"cell_type":"markdown","metadata":{"id":"4fzR7Fu4wrTS"},"source":["A an√°lise do indicador Peso/Idade revela a \"dupla carga da m√° nutri√ß√£o\" que afeta os territ√≥rios ind√≠genas. Por um lado, vemos uma concentra√ß√£o de munic√≠pios (em laranja e azul) onde o principal problema √© a desnutri√ß√£o aguda (Baixo Peso ou Muito Baixo Peso), especialmente nas regi√µes Norte e Centro-Oeste. Por outro lado, uma mancha azul significativa, tamb√©m na Regi√£o Norte (notavelmente Par√° e Amap√°) e espalhada pelo Centro-Oeste e Sul, mostra o Peso Elevado como o problema mais frequente. Isso indica uma transi√ß√£o nutricional prec√°ria, onde a fome coexiste com o aumento do sobrepeso, provavelmente ligado ao acesso a alimentos ultraprocessados e de baixo valor nutritivo em detrimento da alimenta√ß√£o tradicional."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IYDeazFSwrTS"},"outputs":[],"source":["import geopandas as gpd\n","import geobr\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import matplotlib.colors\n","import plotly.express as px\n","\n","# Configura√ß√µes de visualiza√ß√£o\n","sns.set_style(\"whitegrid\")\n","plt.rcParams['figure.figsize'] = (12, 10)\n","plt.rcParams['font.size'] = 12\n","\n","print(\"--- 1. Preparando Dados (com Contagem) ---\")\n","\n","# 1.1. Definir as colunas que representam \"problemas\"\n","categorias_problema = [\n","    'PESO ELEVADO PARA A IDADE',\n","    'BAIXO PESO PARA A IDADE',\n","    'MUITO BAIXO PESO PARA A IDADE'\n","]\n","\n","# 1.2. Filtrar o DataFrame de preval√™ncia para conter APENAS as categorias de problema\n","colunas_presentes = [col for col in prevalencia_por_municipio.columns if col in categorias_problema]\n","df_problemas = prevalencia_por_municipio[colunas_presentes]\n","\n","print(\"Contagem apenas das categorias de 'Problema' (amostra):\")\n","print(df_problemas.head())\n","print(\"\\n\")\n","\n","# --- 1.3: Capturar NOME e CONTAGEM ---\n","# 1.3.a. Achar o NOME do problema mais frequente\n","df_frequente_nome = df_problemas.idxmax(axis=1).to_frame(name='problema_mais_frequente')\n","\n","# 1.3.b. Achar a CONTAGEM do problema mais frequente\n","# .max(axis=1) nos d√° o n√∫mero de crian√ßas da categoria que venceu o idxmax\n","df_frequente_contagem = df_problemas.max(axis=1).to_frame(name='contagem_problema')\n","\n","# 1.3.c. Juntar os dois\n","df_problema_info = df_frequente_nome.join(df_frequente_contagem)\n","\n","print(\"Problema mais frequente E sua contagem (amostra):\")\n","\n","print(df_problema_info.head())\n","print(\"\\n\")\n","\n","\n","# --- 1.4: Usar df_problema_info ---\n","# 1.4. Juntar as informa√ß√µes do problema com o c√≥digo IBGE\n","dados_para_mapa = df_problema_info.merge(\n","    mapa_municipio_ibge,\n","    left_index=True,\n","    right_on='no_municipio'\n",")\n","\n","# Renomear coluna para ficar bonita no tooltip\n","dados_para_mapa.rename(columns={\n","    'contagem_problema': 'N¬∫ de Crian√ßas (Problema Principal)',\n","    'problema_mais_frequente': 'Problema Principal'\n","}, inplace=True)\n","\n","\n","print(\"Dados finais prontos para o merge com o mapa:\")\n","\n","print(dados_para_mapa.head())\n","print(\"\\n\")\n","\n","\n","print(\"--- 2. Carregando Dados Geogr√°ficos (Shapefiles) ---\")\n","try:\n","    gdf_municipios = geobr.read_municipality(year=2020)\n","    print(\"Shapefile dos munic√≠pios do Brasil carregado com sucesso.\")\n","\n","    # 2.1. Ajuste da chave de 7 para 6 d√≠gitos\n","    gdf_municipios['co_ibge_6dig'] = gdf_municipios['code_muni'].astype(str).str[:6].astype(int)\n","    print(\"Coluna 'co_ibge_6dig' criada para o merge.\")\n","    print(\"\\n\")\n","\n","\n","    # --- PASSO 3: Limpeza de Chaves e Merge ---\n","    print(\"--- 3. Limpando Chaves e Unindo Dados ao Mapa ---\")\n","\n","    dados_para_mapa['co_municipio_ibge'] = dados_para_mapa['co_municipio_ibge'].astype(str)\n","    dados_para_mapa['co_municipio_ibge_numeric'] = pd.to_numeric(dados_para_mapa['co_municipio_ibge'], errors='coerce')\n","\n","    nan_values_after_coerce = dados_para_mapa[dados_para_mapa['co_municipio_ibge_numeric'].isna()]\n","    if not nan_values_after_coerce.empty:\n","        print(f\"Encontradas {len(nan_values_after_coerce)} linhas com 'co_municipio_ibge' n√£o num√©rico. Removendo-as.\")\n","        dados_para_mapa.dropna(subset=['co_municipio_ibge_numeric'], inplace=True)\n","\n","    dados_para_mapa.drop(columns=['co_municipio_ibge'], inplace=True)\n","    dados_para_mapa.rename(columns={'co_municipio_ibge_numeric': 'co_municipio_ibge'}, inplace=True)\n","    dados_para_mapa['co_municipio_ibge'] = dados_para_mapa['co_municipio_ibge'].astype(int)\n","\n","    # Fazemos um 'left' merge para manter TODOS os munic√≠pios do Brasil\n","    # Os que n√£o t√™m dados (√† direita) ficar√£o com NaN\n","    mapa_final = gdf_municipios.merge(\n","        dados_para_mapa,\n","        left_on='co_ibge_6dig',\n","        right_on='co_municipio_ibge',\n","        how='left'\n","    )\n","\n","    print(f\"Merge 'left' conclu√≠do. O GeoDataFrame final tem {len(mapa_final)} munic√≠pios.\")\n","\n","    if mapa_final.empty:\n","        print(\"!! ERRO: O merge falhou. !!\")\n","    else:\n","        print(\"\\n--- 4. Plotando o Mapa Interativo com PLOTLY ---\")\n","\n","        # 4.1. Definir o mesmo mapa de cores\n","        color_map = {\n","            'MUITO BAIXO PESO PARA A IDADE': '#b2182b',\n","            'BAIXO PESO PARA A IDADE': '#ef8a62',\n","            'PESO ELEVADO PARA A IDADE': '#4393c3'\n","        }\n","\n","        # 4.2. Criar a figura com Plotly Express\n","        fig = px.choropleth_mapbox(\n","            mapa_final,  # Nosso GeoDataFrame completo (com NaNs)\n","            geojson=mapa_final.geometry,  # Aponta para a coluna de geometria\n","            locations=mapa_final.index, # Identificador √∫nico de cada pol√≠gono\n","\n","            color=\"Problema Principal\",      # Coluna que define as cores\n","            color_discrete_map=color_map, # Nosso dicion√°rio de cores\n","\n","            # Informa√ß√µes que aparecem no Tooltip (ao passar o mouse)\n","            hover_name=\"name_muni\", # Nome do munic√≠pio (vem do geobr)\n","            hover_data={\n","                \"Problema Principal\": True, # Mostra o problema\n","                \"N¬∫ de Crian√ßas (Problema Principal)\": True # Mostra a contagem\n","            },\n","\n","            # Configura√ß√µes do Mapa\n","            mapbox_style=\"carto-positron\", # Estilo de mapa base (limpo)\n","            center={\"lat\": -14.2350, \"lon\": -51.9253}, # Centraliza no Brasil\n","            zoom=3.5,\n","            opacity=0.8 # Leve transpar√™ncia para ver o mapa base\n","        )\n","\n","        # 4.3. Ajustar o layout da legenda\n","        fig.update_layout(\n","            title_text='Principal Problema Nutricional (Peso/Idade) por Munic√≠pio',\n","            legend_title_text='Principal Problema Nutricional<br>(Excluindo \"Peso Adequado\")',\n","            margin={\"r\":0, \"t\":30, \"l\":0, \"b\":0} # Remove margens desnecess√°rias\n","        )\n","\n","        # 4.4. Mostrar o gr√°fico interativo\n","        fig.show()\n","\n","except Exception as e:\n","    print(f\"Ocorreu um erro durante o processo de gera√ß√£o do mapa: {e}\")\n","    print(\"Verifique se as bibliotecas 'geopandas', 'geobr' e 'plotly' est√£o instaladas.\")"]},{"cell_type":"markdown","metadata":{"id":"mS262QmUwrTT"},"source":["### Problemas de desenvolvimento (estatura para idade)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XTY7zen4wrTT"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Configura√ß√µes de visualiza√ß√£o para os gr√°ficos\n","sns.set_style(\"whitegrid\")\n","plt.rcParams['figure.figsize'] = (10, 6)\n","plt.rcParams['font.size'] = 12\n","\n","print(\"\\n--- 1. Preval√™ncia de Estatura para Idade por Munic√≠pio (excluindo NaNs e 'N√ÉO SE APLICA') ---\")\n","\n","# Filtrar o DataFrame para remover NaNs e 'N√ÉO SE APLICA' da coluna 'ds_estatura_idade'\n","df_peso_idade_filtrado = df_criancas[\n","    (df_criancas['ds_estatura_idade'].notna())\n","].copy() # Usar .copy() para evitar SettingWithCopyWarning\n","\n","# Agrupar por munic√≠pio e contar os valores de ds_estatura_idade\n","prevalencia_por_municipio = df_peso_idade_filtrado.groupby('no_municipio')['ds_estatura_idade'].value_counts().unstack(fill_value=0)\n","\n","# Calcular as porcentagens dentro de cada munic√≠pio\n","prevalencia_por_municipio_percentual = prevalencia_por_municipio.apply(lambda x: x / x.sum() * 100, axis=1)\n","\n","print(\"\\nContagem por Munic√≠pio e Diagn√≥stico de Estatura para Idade:\")\n","display(prevalencia_por_municipio.head()) # Exibir as primeiras linhas\n","\n","print(\"\\nPreval√™ncia Percentual por Munic√≠pio e Diagn√≥stico de Estatura para Idade:\")\n","display(prevalencia_por_municipio_percentual.head()) # Exibir as primeiras linhas\n","\n","# Opcional: Visualizar a distribui√ß√£o em alguns munic√≠pios (exemplo com os 5 primeiros)\n","top_municipios = prevalencia_por_municipio.sum(axis=1).nlargest(5).index\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IXmb8abPwrTT"},"outputs":[],"source":["import geopandas as gpd\n","import geobr\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Configura√ß√µes de visualiza√ß√£o\n","sns.set_style(\"whitegrid\")\n","plt.rcParams['figure.figsize'] = (12, 10) # Tamanho maior para mapas\n","plt.rcParams['font.size'] = 12\n","\n","print(\"--- 1. Preparando os dados de Estatura ---\")\n","\n","# 1.1. Filtrar o DataFrame (como voc√™ j√° fez)\n","# Exclui NaNs e 'N√ÉO SE APLICA'\n","df_estatura_idade_filtrado = df_criancas[\n","    (df_criancas['ds_estatura_idade'].notna())\n","].copy()\n","\n","# 1.2. Calcular as contagens por munic√≠pio (como voc√™ j√° fez)\n","prevalencia_por_municipio = df_estatura_idade_filtrado.groupby('no_municipio')['ds_estatura_idade'].value_counts().unstack(fill_value=0)\n","\n","# 1.3. ACHAR A CATEGORIA MAIS FREQUENTE\n","# .idxmax(axis=1) retorna o nome da coluna (categoria) que tem o maior valor em cada linha (munic√≠pio)\n","df_frequente = prevalencia_por_municipio.idxmax(axis=1).to_frame(name='categoria_mais_frequente')\n","\n","print(\"Categoria mais frequente por munic√≠pio:\")\n","\n","print(df_frequente.head())\n","print(\"\\n\")\n","\n","# 1.4. Precisamos do 'co_municipio_ibge' para juntar com o mapa.\n","# Vamos criar um \"mapa\" de 'no_municipio' para 'co_municipio_ibge'\n","# Usamos drop_duplicates para ter apenas uma linha por munic√≠pio\n","mapa_municipio_ibge = df_estatura_idade_filtrado.drop_duplicates(subset=['no_municipio'])[['no_municipio', 'co_municipio_ibge']]\n","\n","\n","# 1.5. Juntar a categoria mais frequente com o c√≥digo IBGE\n","# 'df_frequente' √© indexado por 'no_municipio'\n","dados_para_mapa = df_frequente.merge(\n","    mapa_municipio_ibge,\n","    left_index=True,       # Chave da esquerda (df_frequente) √© o √≠ndice\n","    right_on='no_municipio' # Chave da direita √© a coluna 'no_municipio'\n",")\n","\n","print(\"Dados prontos para o merge com o mapa:\")\n","# display(dados_para_mapa.head())\n","print(dados_para_mapa.head())\n","print(\"\\n\")\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Vo4zCC2twrTU"},"source":["Todos os munic√≠pios parecem ter como categoria mais frequente ESTATURA ADEQUADA PARA A IDADE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SwemNWnowrTU"},"outputs":[],"source":["print(\"--- 2. Testando Varia√ß√£o da Categoria Mais Frequente ---\")\n","\n","# Verifica√ß√£o 1: Usar value_counts() para ver a distribui√ß√£o\n","# Isso mostra exatamente quantas cidades caem em cada categoria principal.\n","print(\"Distribui√ß√£o das categorias mais frequentes:\")\n","contagem_categorias = dados_para_mapa['categoria_mais_frequente'].value_counts()\n","print(contagem_categorias)\n","print(\"\\n\")\n","\n","# Verifica√ß√£o 2: Teste l√≥gico com nunique()\n","# .nunique() retorna apenas o N√öMERO de itens √∫nicos.\n","num_categorias_unicas = dados_para_mapa['categoria_mais_frequente'].nunique()\n","\n","print(f\"Total de munic√≠pios analisados: {len(dados_para_mapa)}\")\n","print(f\"N√∫mero de categorias √∫nicas encontradas: {num_categorias_unicas}\")\n","print(\"\\n\")\n","\n","# Resultado final do teste\n","if num_categorias_unicas == 1:\n","    # .index[0] pega o nome da √∫nica categoria encontrada\n","    categoria_unica = contagem_categorias.index[0]\n","    print(f\"RESULTADO DO TESTE: SIM, todos os {len(dados_para_mapa)} munic√≠pios t√™m o MESMO valor.\")\n","    print(f\"A √∫nica categoria mais frequente √©: '{categoria_unica}'\")\n","elif num_categorias_unicas > 1:\n","    print(f\"RESULTADO DO TESTE: N√ÉO, os munic√≠pios t√™m valores diferentes.\")\n","    print(f\"Foram encontrados {num_categorias_unicas} valores distintos (listados acima).\")\n","    print(\"Portanto, o mapa coropl√©tico mostrar√° varia√ß√£o de cores.\")\n","else:\n","    # Isso s√≥ aconteceria se 'dados_para_mapa' estivesse vazio\n","    print(\"RESULTADO DO TESTE: Nenhum dado encontrado para testar.\")\n","\n","print(\"\\n\" + \"=\"*50)"]},{"cell_type":"markdown","metadata":{"id":"aAVBjBS5wrTU"},"source":["\n","O teste que fizemos no passo anterior procura a categoria mais frequente (a moda) em cada munic√≠pio. O resultado de 'ESTATURA ADEQUADA PARA A IDADE' ser o vencedor em 471 dos 490 munic√≠pios significa simplesmente que, na grande maioria os munic√≠pios, a maioria das crian√ßas (ou pelo menos o maior grupo individual) se enquadra na faixa de normalidade.\n","\n","Isso √© um sinal positivo, mas torna o mapa (o de \"categoria mais frequente\") pouco √∫til, pois ele seria pintado quase completamente de uma cor s√≥, o que poderia inclusive atrapalhar an√°lises interessantes.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"65ylDKoPwrTU"},"source":["Primeiramente vou plotar os munic√≠pios com mais crian√ßas fora da normalidade (desnutri√ß√£o ou sobrepeso) do que dentro da normalidade, para identificar sua localiza√ß√£o.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DMXsewLlwrTU"},"outputs":[],"source":["import geopandas as gpd\n","import geobr\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import matplotlib.colors\n","\n","# Configura√ß√µes de visualiza√ß√£o\n","sns.set_style(\"whitegrid\")\n","plt.rcParams['figure.figsize'] = (12, 10) # Tamanho maior para mapas\n","plt.rcParams['font.size'] = 12\n","\n","print(\"--- 1. Revisitando Contagens e Definindo Categorias ---\")\n","\n","# 1.1. Definir as colunas que representam \"problemas\" de baixa estatura\n","categorias_problema = [\n","    'MUITO BAIXA ESTATURA PARA A IDADE',\n","    'BAIXA ESTATURA PARA A IDADE'\n","]\n","\n","# 1.2. Filtrar o DataFrame de preval√™ncia para conter APENAS as categorias de problema\n","# Usamos .reindex() para garantir que colunas que n√£o existam em algum munic√≠pio\n","# sejam preenchidas com 0, evitando erros.\n","colunas_presentes = [col for col in prevalencia_por_municipio.columns if col in categorias_problema]\n","df_problemas = prevalencia_por_municipio[colunas_presentes]\n","\n","print(\"Contagem apenas das categorias de 'Problema' (amostra):\")\n","# display(df_problemas.head()) # Use display no Jupyter\n","print(df_problemas.head())\n","print(\"\\n\")\n","\n","# 1.3. ACHAR O 'PROBLEMA' MAIS FREQUENTE ENTRE AS CATEGORIAS DE BAIXA ESTATURA\n","# Aplicamos o idxmax neste DataFrame FILTRADO\n","df_frequente_problema = df_problemas.idxmax(axis=1).to_frame(name='problema_mais_frequente')\n","\n","print(\"Problema de estatura mais frequente por munic√≠pio (amostra):\")\n","print(df_frequente_problema.head())\n","print(\"\\n\")\n","\n","# 1.4. Juntar o 'problema mais frequente' com o c√≥digo IBGE\n","dados_para_mapa = df_frequente_problema.merge(\n","    mapa_municipio_ibge,\n","    left_index=True,\n","    right_on='no_municipio'\n",")\n","\n","# Precisamos identificar quais munic√≠pios TINHAM 'ESTATURA ADEQUADA' como o mais frequente no DF original 'df_frequente'\n","municipios_com_estatura_adequada_mais_frequente = df_frequente[\n","    df_frequente['categoria_mais_frequente'] == 'ESTATURA ADEQUADA PARA A IDADE'\n","].index.tolist()\n","\n","# Agora, filtramos o 'dados_para_mapa' para EXCLUIR esses munic√≠pios\n","dados_para_mapa_filtrado = dados_para_mapa[\n","    ~dados_para_mapa['no_municipio'].isin(municipios_com_estatura_adequada_mais_frequente)\n","].copy() # Usar .copy() para evitar SettingWithCopyWarning\n","\n","print(\"Dados finais prontos para o merge com o mapa (ap√≥s filtrar 'Estatura Adequada'):\")\n","print(dados_para_mapa_filtrado.head())\n","print(f\"\\nTotal de munic√≠pios ap√≥s filtro: {len(dados_para_mapa_filtrado)}\")\n","print(\"\\n\")\n","\n","\n","print(\"--- 2. Carregando Dados Geogr√°ficos (Shapefiles) ---\")\n","try:\n","    gdf_municipios = geobr.read_municipality(year=2020)\n","    print(\"Shapefile dos munic√≠pios do Brasil carregado com sucesso.\")\n","\n","    # 2.1. Ajuste da chave de 7 para 6 d√≠gitos\n","    gdf_municipios['co_ibge_6dig'] = gdf_municipios['code_muni'].astype(str).str[:6].astype(int)\n","    print(\"Coluna 'co_ibge_6dig' criada para o merge.\")\n","    print(\"\\n\")\n","\n","    print(\"--- 3. Unindo seus Dados ao Mapa (Merge) ---\")\n","    dados_para_mapa_filtrado['co_municipio_ibge'] = dados_para_mapa_filtrado['co_municipio_ibge'].astype(str)\n","\n","    dados_para_mapa_filtrado['co_municipio_ibge_numeric'] = pd.to_numeric(dados_para_mapa_filtrado['co_municipio_ibge'], errors='coerce')\n","\n","\n","    nan_values_after_coerce = dados_para_mapa_filtrado[dados_para_mapa_filtrado['co_municipio_ibge_numeric'].isna()]\n","    if not nan_values_after_coerce.empty:\n","        print(f\"Found {len(nan_values_after_coerce)} rows with non-numeric 'co_municipio_ibge' after coercing to NaN.\")\n","        print(\"Original non-numeric values:\")\n","        print(nan_values_after_coerce['co_municipio_ibge'].unique())\n","\n","        dados_para_mapa_filtrado.dropna(subset=['co_municipio_ibge_numeric'], inplace=True)\n","        print(\"Dropped rows with non-numeric 'co_municipio_ibge'.\")\n","\n","        dados_para_mapa_filtrado.drop(columns=['co_municipio_ibge'], inplace=True)\n","\n","        dados_para_mapa_filtrado.rename(columns={'co_municipio_ibge_numeric': 'co_municipio_ibge'}, inplace=True)\n","\n","    else:\n","        print(\"No non-numeric values found in 'co_municipio_ibge' after coercing to NaN.\")\n","\n","        dados_para_mapa_filtrado.drop(columns=['co_municipio_ibge'], inplace=True)\n","        dados_para_mapa_filtrado.rename(columns={'co_municipio_ibge_numeric': 'co_municipio_ibge'}, inplace=True)\n","\n","\n","\n","    dados_para_mapa_filtrado['co_municipio_ibge'] = dados_para_mapa_filtrado['co_municipio_ibge'].astype(int)\n","    print(f\"Dtype of 'co_municipio_ibge' in dados_para_mapa_filtrado after converting to int: {dados_para_mapa_filtrado['co_municipio_ibge'].dtype}\")\n","    print(f\"Dtype of 'co_ibge_6dig' in gdf_municipios: {gdf_municipios['co_ibge_6dig'].dtype}\")\n","\n","\n","\n","    mapa_final = gdf_municipios.merge(\n","        dados_para_mapa_filtrado,\n","        left_on='co_ibge_6dig',\n","        right_on='co_municipio_ibge',\n","        how='left'\n","    )\n","\n","\n","    mapa_final_com_dados = mapa_final.dropna(subset=['problema_mais_frequente']).copy()\n","\n","    print(f\"Merge conclu√≠do. Temos {len(mapa_final_com_dados)} munic√≠pios com dados a serem plotados.\")\n","\n","    if mapa_final_com_dados.empty:\n","        print(\"!! N√ÉO H√Å MUNIC√çPIOS PARA PLOTAR AP√ìS O FILTRO !!\")\n","    else:\n","        # --- 4. Plotando o Mapa Coropl√©tico (COM CORES CORRIGIDAS) ---\n","        print(\"\\n--- 4. Plotando o Mapa Coropl√©tico ---\")\n","\n","        # 4.1. Definir um mapa de cores para os PROBLEMAS (Seu mapa est√° correto)\n","        color_map = {\n","            'MUITO BAIXA ESTATURA PARA A IDADE': '#b2182b', # Vermelho Escuro\n","            'BAIXA ESTATURA PARA A IDADE': '#ef8a62'     # Laranja/Vermelho Claro\n","        }\n","\n","\n","        # 4.2. Criar o Colormap na ORDEM ALFAB√âTICA correta\n","        # Primeiro, pegamos as categorias √∫nicas que REALMENTE est√£o nos seus dados\n","        # e as ORDENAMOS alfabeticamente (com sorted())\n","        categorias_presentes_ordenadas = sorted(\n","            mapa_final_com_dados['problema_mais_frequente'].dropna().unique()\n","        )\n","\n","        print(f\"Ordem das categorias que o Geopandas vai usar: {categorias_presentes_ordenadas}\")\n","\n","        # Segundo, criamos a LISTA de cores usando essa ordem alfab√©tica\n","        # (Garante que '#ef8a62' venha antes de '#b2182b')\n","        lista_de_cores_ordenadas = [\n","            color_map[categoria] for categoria in categorias_presentes_ordenadas\n","        ]\n","\n","        print(f\"Lista de cores na ordem correta: {lista_de_cores_ordenadas}\")\n","\n","        # Terceiro, criamos o ListedColormap\n","        cmap = matplotlib.colors.ListedColormap(lista_de_cores_ordenadas)\n","\n","\n","        # 4.3. Plotar os gr√°ficos (Seu c√≥digo original)\n","        fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n","\n","\n","        gdf_municipios.plot(ax=ax, color='lightgray', edgecolor='black', linewidth=0.1)\n","\n","\n","        mapa_final_com_dados.plot(\n","            column='problema_mais_frequente', # Coluna que define as cores\n","            categorical=True,                 # Essencial para categorias\n","            cmap=cmap,\n","            legend=True,\n","            legend_kwds={\n","                'title': 'Principal Problema de Estatura \\n(Excluindo \"Estatura Adequada\")',\n","                'bbox_to_anchor': (1.05, 1),\n","                'loc': 'upper left'\n","            },\n","            ax=ax,\n","            edgecolor='black',\n","            linewidth=0.1\n","        )\n","\n","\n","        ax.set_title('Principal Problema de Estatura (Altura/Idade) por Munic√≠pio', fontsize=16)\n","        ax.axis('off')\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","except Exception as e:\n","    print(f\"Ocorreu um erro durante o processo de gera√ß√£o do mapa: {e}\")\n","    print(\"Verifique se as bibliotecas 'geopandas' e 'geobr' est√£o instaladas.\")"]},{"cell_type":"markdown","metadata":{"id":"al_h221-wrTV"},"source":["Os munic√≠pios com esse perfil parecem se concentrar muito na regi√£o Norte. Para al√©m, a maioria deles apresenta como perfil majorit√°rio MUITO BAIXA ESTATURA PARA IDADE, indicando que, quando a maioria das crian√ßas n√£o est√° na normalidade, a estatura delas n√£o √© apenas baixa, mas alarmantemente baixa."]},{"cell_type":"markdown","metadata":{"id":"9no0wMABwrTV"},"source":["Agora, a pergunta anal√≠tica mais rica √©: \"Ok, se ignorarmos as crian√ßas com estatura adequada, qual √© o problema nutricional mais comum em cada munic√≠pio?\"\n","\n","Estamos essencialmente \"dando zoom\" nos dados, filtrando a normalidade para focar nos desvios:\n","\n","'BAIXA ESTATURA PARA A IDADE'\n","'MUITO BAIXA ESTATURA PARA A IDADE'\n","\n","Ao fazer isso, conseguiremos criar um mapa que mostra clusters geogr√°ficos.\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YjRBvMViwrTV"},"outputs":[],"source":["import geopandas as gpd\n","import geobr\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import matplotlib.colors\n","\n","# Configura√ß√µes de visualiza√ß√£o\n","sns.set_style(\"whitegrid\")\n","plt.rcParams['figure.figsize'] = (12, 10) # Tamanho maior para mapas\n","plt.rcParams['font.size'] = 12\n","\n","print(\"--- 1. Revisitando Contagens e Definindo Categorias ---\")\n","\n","\n","# 1.1. Definir as colunas que representam \"problemas\"\n","categorias_problema = [\n","    'MUITO BAIXA ESTATURA PARA A IDADE',\n","    'BAIXA ESTATURA PARA A IDADE'\n","]\n","\n","# 1.2. Filtrar o DataFrame de preval√™ncia para conter APENAS as categorias de problema\n","# 'prevalencia_por_municipio' deve ter sido calculado antes (no script de Peso/Idade)\n","colunas_presentes = [col for col in prevalencia_por_municipio.columns if col in categorias_problema]\n","df_problemas = prevalencia_por_municipio[colunas_presentes]\n","\n","print(\"Contagem apenas das categorias de 'Problema' (amostra):\")\n","print(df_problemas.head())\n","print(\"\\n\")\n","\n","# 1.3. ACHAR O 'PROBLEMA' MAIS FREQUENTE\n","df_frequente_problema = df_problemas.idxmax(axis=1).to_frame(name='problema_mais_frequente')\n","\n","print(\"Problema de estatura mais frequente por munic√≠pio (amostra):\")\n","print(df_frequente_problema.head())\n","print(\"\\n\")\n","\n","# 1.4. Juntar o 'problema mais frequente' com o c√≥digo IBGE\n","# 'mapa_municipio_ibge' deve ter sido calculado antes\n","dados_para_mapa = df_frequente_problema.merge(\n","    mapa_municipio_ibge,\n","    left_index=True,\n","    right_on='no_municipio'\n",")\n","\n","print(\"Dados finais prontos para o merge com o mapa:\")\n","print(dados_para_mapa.head())\n","print(\"\\n\")\n","\n","\n","print(\"--- 2. Carregando Dados Geogr√°ficos (Shapefiles) ---\")\n","try:\n","\n","    if 'gdf_municipios' not in locals():\n","        gdf_municipios = geobr.read_municipality(year=2020)\n","        print(\"Shapefile dos munic√≠pios do Brasil carregado com sucesso.\")\n","        # 2.1. Ajuste da chave de 7 para 6 d√≠gitos\n","        gdf_municipios['co_ibge_6dig'] = gdf_municipios['code_muni'].astype(str).str[:6].astype(int)\n","        print(\"Coluna 'co_ibge_6dig' criada para o merge.\")\n","    else:\n","        print(\"Shapefile 'gdf_municipios' j√° estava em mem√≥ria.\")\n","    print(\"\\n\")\n","\n","    print(\"--- 3. Unindo seus Dados ao Mapa (Merge) ---\")\n","    # Limpeza de chaves\n","    dados_para_mapa['co_municipio_ibge'] = dados_para_mapa['co_municipio_ibge'].astype(str)\n","    dados_para_mapa['co_municipio_ibge_numeric'] = pd.to_numeric(dados_para_mapa['co_municipio_ibge'], errors='coerce')\n","    nan_values_after_coerce = dados_para_mapa[dados_para_mapa['co_municipio_ibge_numeric'].isna()]\n","    if not nan_values_after_coerce.empty:\n","        print(f\"Encontradas {len(nan_values_after_coerce)} linhas com 'co_municipio_ibge' n√£o num√©rico. Removendo-as.\")\n","        dados_para_mapa.dropna(subset=['co_municipio_ibge_numeric'], inplace=True)\n","    dados_para_mapa.drop(columns=['co_municipio_ibge'], inplace=True)\n","    dados_para_mapa.rename(columns={'co_municipio_ibge_numeric': 'co_municipio_ibge'}, inplace=True)\n","    dados_para_mapa['co_municipio_ibge'] = dados_para_mapa['co_municipio_ibge'].astype(int)\n","\n","\n","    mapa_final = gdf_municipios.merge(\n","        dados_para_mapa,\n","        left_on='co_ibge_6dig',\n","        right_on='co_municipio_ibge'\n","    )\n","\n","    print(f\"Merge conclu√≠do. Temos {len(mapa_final)} munic√≠pios com dados.\")\n","\n","    if mapa_final.empty:\n","        print(\"!! ERRO: O merge n√£o encontrou munic√≠pios em comum. !!\")\n","    else:\n","        # --- 4. Plotando o Mapa Coropl√©tico  ---\n","        print(\"\\n--- 4. Plotando o Mapa Coropl√©tico ---\")\n","\n","        # 4.1. Definir um mapa de cores para os PROBLEMAS\n","        color_map = {\n","            'MUITO BAIXA ESTATURA PARA A IDADE': '#b2182b', # Vermelho Escuro\n","            'BAIXA ESTATURA PARA A IDADE': '#ef8a62'     # Laranja/Vermelho Claro\n","        }\n","\n","\n","        # 4.2. Criar o Colormap na ORDEM ALFAB√âTICA correta\n","        # Ordenamos as categorias alfabeticamente\n","        categorias_presentes_ordenadas = sorted(\n","            mapa_final['problema_mais_frequente'].dropna().unique()\n","        )\n","        print(f\"Ordem das categorias que o Geopandas vai usar: {categorias_presentes_ordenadas}\")\n","\n","        # Criamos a LISTA de cores usando essa ordem\n","        lista_de_cores_ordenadas = [\n","            color_map[categoria] for categoria in categorias_presentes_ordenadas\n","        ]\n","        print(f\"Lista de cores na ordem correta: {lista_de_cores_ordenadas}\")\n","\n","        # Criamos o ListedColormap\n","        cmap = matplotlib.colors.ListedColormap(lista_de_cores_ordenadas)\n","\n","\n","        # 4.3. Plotar os gr√°ficos\n","        fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n","\n","        # Plot the base map with all municipality borders\n","        gdf_municipios.plot(ax=ax, color='lightgray', edgecolor='black', linewidth=0.1)\n","\n","        # Plot the data on top of the base map\n","        mapa_final.plot(\n","            column='problema_mais_frequente', # Coluna que define as cores\n","            categorical=True,                 # Essencial para categorias\n","            cmap=cmap,                        # Use o Colormap ordenado\n","            legend=True,\n","            legend_kwds={\n","                'title': 'Principal Problema de Estatura \\n(Excluindo \"Estatura Adequada\")',\n","                'bbox_to_anchor': (1.05, 1),\n","                'loc': 'upper left'\n","            },\n","            ax=ax,\n","            edgecolor='black',\n","            linewidth=0.1\n","        )\n","\n","\n","        ax.set_title('Principal Problema de Estatura (Altura/Idade) por Munic√≠pio', fontsize=16)\n","        ax.axis('off')\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","except Exception as e:\n","    print(f\"Ocorreu um erro durante o processo de gera√ß√£o do mapa: {e}\")\n","    print(\"Verifique se as bibliotecas 'geopandas' e 'geobr' est√£o instaladas.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nwxg-ZbJwrTV"},"outputs":[],"source":["import geopandas as gpd\n","import geobr\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import matplotlib.colors\n","import plotly.express as px\n","\n","# Configura√ß√µes de visualiza√ß√£o\n","sns.set_style(\"whitegrid\")\n","plt.rcParams['figure.figsize'] = (12, 10)\n","plt.rcParams['font.size'] = 12\n","\n","# --- PASSO 0: Recalcular a Preval√™ncia para ESTATURA ---\n","\n","print(\"--- 0. Calculando Preval√™ncia de ESTATURA ---\")\n","\n","# 1. Filtrar o DataFrame original para ESTATURA\n","df_estatura_filtrado = df_criancas[\n","    (df_criancas['ds_estatura_idade'].notna()) &\n","    (df_criancas['ds_estatura_idade'] != 'N√ÉO SE APLICA')\n","].copy()\n","\n","# 2. CALCULAR a preval√™ncia por munic√≠pio PARA ESTATURA\n","# Isto ir√° SOBRESCREVER a vari√°vel antiga (de peso) com os dados corretos (de estatura)\n","prevalencia_por_municipio = df_estatura_filtrado.groupby('no_municipio')['ds_estatura_idade'].value_counts().unstack(fill_value=0)\n","\n","# 3. Recalcular o mapa_municipio_ibge tamb√©m, para garantir\n","mapa_municipio_ibge = df_estatura_filtrado.drop_duplicates(subset=['no_municipio'])[['no_municipio', 'co_municipio_ibge']]\n","\n","print(\"Preval√™ncia de ESTATURA por Munic√≠pio (amostra):\")\n","# display(prevalencia_por_municipio.head())\n","print(prevalencia_por_municipio.head())\n","print(\"\\n\" + \"=\"*50 + \"\\n\")\n","\n","\n","# --- IN√çCIO DO SCRIPT ADAPTADO ---\n","\n","print(\"--- 1. Preparando Dados de Estatura (com Contagem) ---\")\n","\n","# 1.1. Definir as colunas que representam \"problemas\" de ESTATURA\n","categorias_problema = [\n","    'MUITO BAIXA ESTATURA PARA A IDADE',\n","    'BAIXA ESTATURA PARA A IDADE'\n","]\n","\n","# 1.2. Filtrar o DataFrame de preval√™ncia (agora de Estatura)\n","colunas_presentes = [col for col in prevalencia_por_municipio.columns if col in categorias_problema]\n","df_problemas = prevalencia_por_municipio[colunas_presentes]\n","\n","print(\"Contagem apenas das categorias de 'Problema' (amostra):\")\n","print(df_problemas.head())\n","print(\"\\n\")\n","\n","# --- 1.3: Capturar NOME e CONTAGEM  ---\n","df_frequente_nome = df_problemas.idxmax(axis=1).to_frame(name='problema_mais_frequente')\n","df_frequente_contagem = df_problemas.max(axis=1).to_frame(name='contagem_problema')\n","df_problema_info = df_frequente_nome.join(df_frequente_contagem)\n","\n","print(\"Problema mais frequente E sua contagem (amostra):\")\n","print(df_problema_info.head())\n","print(\"\\n\")\n","\n","\n","# --- 1.4: Usar df_problema_info  ---\n","dados_para_mapa = df_problema_info.merge(\n","    mapa_municipio_ibge,\n","    left_index=True,\n","    right_on='no_municipio'\n",")\n","\n","# Renomear colunas para o tooltip\n","dados_para_mapa.rename(columns={\n","    'contagem_problema': 'N¬∫ de Crian√ßas (Problema Principal)',\n","    'problema_mais_frequente': 'Problema Principal'\n","}, inplace=True)\n","\n","\n","print(\"Dados finais prontos para o merge com o mapa:\")\n","print(dados_para_mapa.head())\n","print(\"\\n\")\n","\n","\n","print(\"--- 2. Carregando Dados Geogr√°ficos (Shapefiles) ---\")\n","try:\n","    # Otimiza√ß√£o: S√≥ baixar se n√£o existir na mem√≥ria\n","    if 'gdf_municipios' not in locals():\n","        gdf_municipios = geobr.read_municipality(year=2020)\n","        print(\"Shapefile dos munic√≠pios do Brasil carregado com sucesso.\")\n","        # 2.1. Ajuste da chave de 7 para 6 d√≠gitos\n","        gdf_municipios['co_ibge_6dig'] = gdf_municipios['code_muni'].astype(str).str[:6].astype(int)\n","        print(\"Coluna 'co_ibge_6dig' criada para o merge.\")\n","    else:\n","        print(\"Shapefile 'gdf_municipios' j√° estava em mem√≥ria.\")\n","    print(\"\\n\")\n","\n","\n","    # --- PASSO 3: Limpeza de Chaves e Merge ---\n","    print(\"--- 3. Limpando Chaves e Unindo Dados ao Mapa ---\")\n","\n","    dados_para_mapa['co_municipio_ibge'] = dados_para_mapa['co_municipio_ibge'].astype(str)\n","    dados_para_mapa['co_municipio_ibge_numeric'] = pd.to_numeric(dados_para_mapa['co_municipio_ibge'], errors='coerce')\n","\n","    nan_values_after_coerce = dados_para_mapa[dados_para_mapa['co_municipio_ibge_numeric'].isna()]\n","    if not nan_values_after_coerce.empty:\n","        print(f\"Encontradas {len(nan_values_after_coerce)} linhas com 'co_municipio_ibge' n√£o num√©rico. Removendo-as.\")\n","        dados_para_mapa.dropna(subset=['co_municipio_ibge_numeric'], inplace=True)\n","\n","    dados_para_mapa.drop(columns=['co_municipio_ibge'], inplace=True)\n","    dados_para_mapa.rename(columns={'co_municipio_ibge_numeric': 'co_municipio_ibge'}, inplace=True)\n","    dados_para_mapa['co_municipio_ibge'] = dados_para_mapa['co_municipio_ibge'].astype(int)\n","\n","    # Merge 'left' para manter o mapa do Brasil inteiro\n","    mapa_final = gdf_municipios.merge(\n","        dados_para_mapa,\n","        left_on='co_ibge_6dig',\n","        right_on='co_municipio_ibge',\n","        how='left'\n","    )\n","\n","    print(f\"Merge 'left' conclu√≠do. O GeoDataFrame final tem {len(mapa_final)} munic√≠pios.\")\n","\n","    if mapa_final.empty:\n","        print(\"!! ERRO: O merge falhou. !!\")\n","    else:\n","        print(\"\\n--- 4. Plotando o Mapa Interativo de ESTATURA com PLOTLY ---\")\n","\n","        # 4.1. Definir o mapa de cores para ESTATURA\n","        color_map = {\n","            'MUITO BAIXA ESTATURA PARA A IDADE': '#b2182b', # Vermelho Escuro\n","            'BAIXA ESTATURA PARA A IDADE': '#ef8a62'     # Laranja/Vermelho Claro\n","        } # <-- MUDAN√áA\n","\n","        # 4.2. Criar a figura com Plotly Express\n","        fig = px.choropleth_mapbox(\n","            mapa_final,\n","            geojson=mapa_final.geometry,\n","            locations=mapa_final.index,\n","\n","            color=\"Problema Principal\",\n","            color_discrete_map=color_map, # <-- Usa o novo color_map\n","\n","            hover_name=\"name_muni\",\n","            hover_data={\n","                \"Problema Principal\": True,\n","                \"N¬∫ de Crian√ßas (Problema Principal)\": True\n","            },\n","\n","            mapbox_style=\"carto-positron\",\n","            center={\"lat\": -14.2350, \"lon\": -51.9253},\n","            zoom=3.5,\n","            opacity=0.8\n","        )\n","\n","        # 4.3. Ajustar o layout da legenda e t√≠tulo\n","        fig.update_layout(\n","            title_text='Principal Problema de Estatura (Altura/Idade) por Munic√≠pio', # <-- MUDAN√áA\n","            legend_title_text='Principal Problema de Estatura<br>(Excluindo \"Estatura Adequada\")', # <-- MUDAN√áA\n","            margin={\"r\":0, \"t\":30, \"l\":0, \"b\":0}\n","        )\n","\n","        # 4.4. Mostrar o gr√°fico interativo\n","        fig.show()\n","\n","except Exception as e:\n","    print(f\"Ocorreu um erro durante o processo de gera√ß√£o do mapa: {e}\")\n","    print(\"Verifique se as bibliotecas 'geopandas', 'geobr' e 'plotly' est√£o instaladas.\")"]},{"cell_type":"markdown","metadata":{"id":"Xiu3P1yq2_QZ"},"source":["# ü§Ø Parte 3"]},{"cell_type":"code","source":["from scipy import stats\n","from scipy.stats import chi2_contingency\n","import sys"],"metadata":{"id":"BZu0t5MHN-ex"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HbcobhmO3MDw"},"source":["## 3.1. An√°lise Bivariada - Teste de Hip√≥teses 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sRjc5Svp3C9w"},"outputs":[],"source":["from scipy import stats\n","import numpy as np\n","\n","print(\"--- Teste T: Diferen√ßa de Alturas (H0: M√©dia F - M√©dia M = 0) ---\\n\")\n","\n","#Hip√≥teses\n","\n","print(\"H0: M√©dia(F) - M√©dia(M) = 0\")\n","print(\"HA: M√©dia(F) - M√©dia(M) ‚â† 0\\n\")\n","\n","#Prepara√ß√£o dos Dados\n","altura_masc = df_criancas.loc[df_criancas['tp_sexo'] == 'M', 'nu_altura'].dropna()\n","altura_fem  = df_criancas.loc[df_criancas['tp_sexo'] == 'F', 'nu_altura'].dropna()\n","\n","# An√°lise Descritiva\n","print(f\"Registros v√°lidos (M): {len(altura_masc)}\")\n","print(f\"Registros v√°lidos (F): {len(altura_fem)}\")\n","print(f\"M√©dia Masculino (M): {altura_masc.mean():.2f} cm\")\n","print(f\"M√©dia Feminino (F):  {altura_fem.mean():.2f} cm\\n\")\n","\n","#Teste T\n","t_stat, p_val = stats.ttest_ind(\n","    altura_fem,\n","    altura_masc,\n","    equal_var=False,\n","    nan_policy='omit'\n",")\n","\n","print(\"--- Resultado do Teste T ---\")\n","print(f\"Estat√≠stica T: {t_stat:.4f}\")\n","print(f\"P-Valor: {p_val:.6f}\\n\")\n","\n","#Graus de liberdade aproximados (f√≥rmula de Welch-Satterthwaite)\n","s1, s2 = np.var(altura_fem, ddof=1), np.var(altura_masc, ddof=1)\n","n1, n2 = len(altura_fem), len(altura_masc)\n","df_welch = (s1/n1 + s2/n2)**2 / ((s1**2)/((n1**2)*(n1-1)) + (s2**2)/((n2**2)*(n2-1)))\n","\n","#Intervalo de Confian√ßa (95%)\n","media_dif = altura_fem.mean() - altura_masc.mean()\n","erro_padrao = np.sqrt(s1/n1 + s2/n2)\n","t_critico = stats.t.ppf(1 - 0.05/2, df_welch)\n","ic_inf = media_dif - t_critico * erro_padrao\n","ic_sup = media_dif + t_critico * erro_padrao\n","\n","print(\"--- Intervalo de Confian√ßa (95%) ---\")\n","print(f\"Graus de liberdade (Welch): {df_welch:.2f}\")\n","print(f\"Erro Padr√£o da Diferen√ßa: {erro_padrao:.4f}\")\n","print(f\"IC 95% para (M√©dia F - M√©dia M): ({ic_inf:.4f}, {ic_sup:.4f}) cm\\n\")\n","\n","# Decis√£o\n","if abs(t_stat) > t_critico:\n","    print(\"Decis√£o: Rejeitamos H0.\")\n","    print(\"Conclus√£o: Existe diferen√ßa estatisticamente significativa entre as alturas m√©dias de meninos e meninas.\")\n","else:\n","    print(\"Decis√£o: Falhamos em rejeitar H0.\")\n","    print(\"Conclus√£o: N√£o h√° evid√™ncias de diferen√ßa significativa entre as alturas m√©dias de meninos e meninas.\")\n"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","print(\"Plotando Histogramas de Altura por Sexo\")\n","\n","\n","# Definir os sexos v√°lidos\n","sexos_validos = ['M', 'F']\n","\n","# Filtrar o DataFrame principal\n","df_plot = df_criancas[\n","    (df_criancas['tp_sexo'].isin(sexos_validos)) &\n","    (df_criancas['nu_altura'].notna())\n","].copy()\n","\n","# Calcular as M√©dias\n","# (O Teste T j√° fez isso, mas vamos recalcular para ter certeza)\n","media_m = df_plot.loc[df_plot['tp_sexo'] == 'M', 'nu_altura'].mean()\n","media_f = df_plot.loc[df_plot['tp_sexo'] == 'F', 'nu_altura'].mean()\n","\n","print(f\"M√©dia (M) para o gr√°fico: {media_m:.2f} cm\")\n","print(f\"M√©dia (F) para o gr√°fico: {media_f:.2f} cm\")\n","\n","#Criar o Gr√°fico\n","plt.figure(figsize=(12, 7))\n","sns.set_style(\"whitegrid\")\n","\n","\n","sns.histplot(\n","    data=df_plot,\n","    x='nu_altura',\n","    hue='tp_sexo',\n","    stat=\"density\",\n","    kde=True,\n","    common_norm=False,\n","    bins=50,  # Voc√™ pode ajustar o n√∫mero de barras\n","    alpha=0.4 # N√≠vel de transpar√™ncia das barras\n",")\n","\n","# Adicionar Linhas Verticais para as M√©dias\n","plt.axvline(media_m, color=sns.color_palette()[0], linestyle='--', linewidth=2)\n","plt.axvline(media_f, color=sns.color_palette()[1], linestyle='--', linewidth=2)\n","\n","# Adicionar texto para as m√©dias\n","plt.text(media_m + 1, 0.025, f'M√©dia M:\\n{media_m:.2f} cm', color=sns.color_palette()[0])\n","plt.text(media_f - 11, 0.025, f'M√©dia F:\\n{media_f:.2f} cm', color=sns.color_palette()[1])\n","\n","\n","\n","plt.title('Compara√ß√£o da Distribui√ß√£o de Altura (cm) por Sexo', fontsize=16)\n","plt.xlabel('Altura (cm)', fontsize=12)\n","plt.ylabel('Densidade', fontsize=12)\n","\n","plt.legend(title='Sexo', labels=['Feminino (F)', 'Masculino (M)'])\n","\n","plt.tight_layout()\n","plt.savefig(\"altura_sexo_histograma.png\")\n","print(\"\\nGr√°fico 'altura_sexo_histograma.png' salvo.\")"],"metadata":{"id":"K2UjHKpsXkZb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kbsjK0Ot3YeV"},"source":["## 3.2. RQ3: Aleitamento e Estado Nutricional - Teste de Hip√≥teses 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OcjoX_Ty3ZkY"},"outputs":[],"source":["print(\"--- Executando Teste Qui-Quadrado ---\")\n","\n","#Prepara√ß√£o\n","df_chi2 = df_criancas[\n","    (df_criancas['tipo_aleitamento'] != 'DESCONHECIDO') &\n","    (df_criancas['tipo_aleitamento'].notna()) &\n","    (df_criancas['ds_peso_idade'] != 'N√ÉO SE APLICA') &\n","    (df_criancas['ds_peso_idade'].notna())\n","]\n","tabela_contingencia = pd.crosstab(\n","    df_chi2['tipo_aleitamento'],\n","    df_chi2['ds_peso_idade']\n",")\n","\n","#Execu√ß√£o do Teste\n","chi2_stat, p_value, dof, expected_freqs = chi2_contingency(tabela_contingencia)\n","\n","print(\"Resultado do Teste Qui-Quadrado\")\n","print(f\"Estat√≠stica Qui-Quadrado: {chi2_stat:.4f}\")\n","print(f\"Graus de Liberdade (dof): {dof}\")\n","\n","#Interpreta√ß√£o do P-valor\n","print(\"An√°lise do P-Valor\")\n","print(f\"Valor 'cru' da vari√°vel p_value: {p_value}\")\n","\n","# Pega o menor n√∫mero positivo que o Python pode representar\n","menor_numero_float = sys.float_info.min\n","\n","if p_value == 0.0:\n","    print(f\"Como reportar: 'p < {menor_numero_float:g}' (ou simplesmente 'p < .001')\")\n","else:\n","    print(f\"P-Valor (precis√£o total): {p_value:e}\")\n","\n","print(\"Conclus√£o Final\")\n","alpha = 0.05\n","if p_value < alpha:\n","    print(f\"Resultado (p < {alpha}): Rejeitamos a Hip√≥tese Nula (H0).\")\n","    print(\"Conclus√£o: Existe uma associa√ß√£o estatisticamente significativa entre o tipo de aleitamento e o estado nutricional (peso/idade).\")\n","else:\n","    print(f\"Resultado (p >= {alpha}): Falhamos em Rejeitar a Hip√≥tese Nula (H0).\")\n","    print(\"Conclus√£o: N√£o h√° evid√™ncia estat√≠stica suficiente para afirmar que existe uma associa√ß√£o entre as vari√°veis.\")"]},{"cell_type":"code","source":["\n","\n","alpha = 0.05 # Nosso n√≠vel de signific√¢ncia (95% de confian√ßa)\n","\n","valor_critico = stats.chi2.ppf(1 - alpha, df=dof)\n","\n","print(\"--- Teste de Hip√≥tese pelo Valor Cr√≠tico ---\")\n","print(f\"N√≠vel de Signific√¢ncia (alpha): {alpha}\")\n","print(f\"Graus de Liberdade (dof): {dof}\")\n","print(\"\\n\")\n","print(f\"   Estat√≠stica Qui-Quadrado : {chi2_stat:.4f}\")\n","print(f\"   Valor Cr√≠tico (A 'Linha de Corte'): {valor_critico:.4f}\")\n","print(\"\\n\")\n","\n","# --- 3. A Regra da Decis√£o ---\n","if chi2_stat > valor_critico:\n","    print(\"Resultado: Nossa pontua√ß√£o √© MAIOR que a linha de corte.\")\n","    print(\"Decis√£o: Rejeitamos a Hip√≥tese Nula (H0).\")\n","    print(\"\\nConclus√£o: Existe uma associa√ß√£o estatisticamente significativa.\")\n","else:\n","    print(\"Resultado: Nossa pontua√ß√£o √© MENOR ou IGUAL √† linha de corte.\")\n","    print(\"Decis√£o: Falhamos em Rejeitar a Hip√≥tese Nula (H0).\")\n","    print(\"\\nConclus√£o: N√£o h√° evid√™ncia de associa√ß√£o.\")"],"metadata":{"id":"YFvsyq74Piy4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.stats import chi2\n","\n","# --- 1. Nossos Par√¢metros ---\n","dof = 9\n","chi2_stat_obs = 5338.1226\n","valor_critico = 16.9190\n","alpha = 0.05\n","\n","# --- 2. Preparar o Eixo X para o Gr√°fico ---\n","x_max_plot = 35\n","x = np.linspace(0, x_max_plot, 500)\n","pdf = chi2.pdf(x, df=dof)\n","\n","# --- 3. Criar o Plot ---\n","plt.figure(figsize=(12, 7))\n","\n","# CORRE√á√ÉO 1: Adicionado 'r' antes do f' (rf')\n","plt.plot(x, pdf, label=rf'Distribui√ß√£o $\\chi^2$ (dof={dof})', color='black', linewidth=2)\n","\n","# --- 4. Sombrear a Cauda (Regi√£o de Rejei√ß√£o) ---\n","x_tail = np.linspace(valor_critico, x_max_plot, 100)\n","pdf_tail = chi2.pdf(x_tail, df=dof)\n","\n","plt.fill_between(\n","    x_tail,\n","    pdf_tail,\n","    color='red',\n","    alpha=0.5,\n","    label=f'Regi√£o de Rejei√ß√£o (p < {alpha})'\n",")\n","\n","# --- 5. Desenhar as Linhas e Anota√ß√µes ---\n","plt.axvline(valor_critico, color='red', linestyle='--', linewidth=2)\n","plt.annotate(\n","    f'Valor Cr√≠tico = {valor_critico:.2f}\\n(In√≠cio da Cauda)',\n","    xy=(valor_critico, 0.005),\n","    xytext=(valor_critico + 2, 0.03),\n","    arrowprops=dict(facecolor='red', shrink=0.05, width=1, headwidth=5),\n","    ha='left',\n","    color='red'\n",")\n","\n","# CORRE√á√ÉO 2: Adicionado 'r' antes do f' (rf')\n","plt.annotate(\n","    rf'Nosso Valor Observado:' + f'\\n{chi2_stat_obs:.2f}\\n(Muito fora do gr√°fico $\\longrightarrow$)', # Quebrei a string para o rf' funcionar\n","    xy=(32, 0.015),\n","    xytext=(26, 0.05),\n","    arrowprops=dict(facecolor='blue', shrink=0.05, width=1, headwidth=5, connectionstyle=\"angle3,angleA=0,angleB=-90\"),\n","    fontsize=12,\n","    ha='center',\n","    color='blue',\n","    fontweight='bold'\n",")\n","\n","# --- 6. Limpar o Gr√°fico ---\n","plt.title('Visualiza√ß√£o do Teste Qui-Quadrado (dof=9)', fontsize=16)\n","\n","# CORRE√á√ÉO 3: Adicionado 'r' antes do '...' (r')\n","plt.xlabel(r'Valor da Estat√≠stica Qui-Quadrado ($\\chi^2$)', fontsize=12)\n","plt.ylabel('Densidade de Probabilidade', fontsize=12)\n","plt.legend(loc='upper right')\n","plt.grid(True, linestyle=':', alpha=0.7)\n","\n","plt.xlim(0, x_max_plot)\n","plt.ylim(bottom=0)\n","\n","plt.tight_layout()\n","plt.show() # Mostra o gr√°fico"],"metadata":{"id":"rhxpo2gw-NzG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oftCnsOm9Pio"},"source":["## 3.3. RQ4: Impacto Combinado no Crescimento - Regress√£o Linear"]},{"cell_type":"markdown","source":["A import√¢ncia desta Regress√£o Linear M√∫ltipla reside na sua capacidade de ir al√©m das an√°lises descritivas, permitindo-nos **quantificar o impacto combinado e isolado** de m√∫ltiplos fatores sobre o crescimento infantil. Usando a altura (`nu_altura`) como vari√°vel-alvo, estamos a modelar o principal indicador da **desnutri√ß√£o cr√¥nica** (nanismo), um problema de sa√∫de p√∫blica fundamental."],"metadata":{"id":"TtyIy9IkFUBg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"o-5DG46-9QaX"},"outputs":[],"source":["df_criancas.columns"]},{"cell_type":"markdown","source":["Alvo (Y): nu_altura\n","\n","Preditoras (X) para o modelo (candidatas): idade_meses_atend, tp_sexo, tipo_aleitamento, nu_peso, dsei_gestao, sg_uf, no_categoria_subcategoria e ds_cbo_familia."],"metadata":{"id":"kWtRIXxVnerG"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","print(\"--- Iniciando Fase 1 (Prepara√ß√£o RQ4 - Fase de Constru√ß√£o) ---\")\n","\n","# Verificando se df_criancas est√° na mem√≥ria\n","if 'df_criancas' not in locals():\n","    print(\"ERRO: DataFrame 'df_criancas' n√£o encontrado.\")\n","    print(\"Por favor, carregue 'dados_consolidados_criancas.csv' primeiro.\")\n","else:\n","    print(\"DataFrame 'df_criancas' encontrado na mem√≥ria.\")\n","\n","    # 1. Definir as colunas candidatas para a fase de constru√ß√£o\n","    colunas_para_construcao = [\n","        # Alvo (Y)\n","        'nu_altura',\n","\n","        # Preditoras (X) - N√∫cleo\n","        'idade_meses_atend',\n","        'tp_sexo',\n","        'tipo_aleitamento',\n","        'nu_peso', # O que voc√™ pediu para incluir\n","\n","        # Preditoras (X) - Alternativas Geogr√°ficas\n","        'dsei_gestao',\n","        'sg_uf',\n","\n","        # Preditoras (X) - Alternativas Cl√≠nicas/Sa√∫de\n","        'no_categoria_subcategoria', # Morbidade (doen√ßa)\n","        'ds_cbo_familia'             # Profissional que atendeu\n","    ]\n","\n","    # --- 2. Checando se todas as colunas necess√°rias existem ---\n","    print(\"\\n--- 2. Checando colunas necess√°rias ---\")\n","    colunas_ausentes = [col for col in colunas_para_construcao if col not in df_criancas.columns]\n","\n","    if len(colunas_ausentes) > 0:\n","        print(f\"!!! ERRO: As seguintes colunas N√ÉO existem no 'df_criancas': {colunas_ausentes}\")\n","        print(\"A prepara√ß√£o n√£o pode continuar.\")\n","    else:\n","        print(\"-> SUCESSO: Todas as colunas do modelo est√£o presentes.\")\n","\n","        # --- 3. Finalizando o DataFrame (Limpando NaNs) ---\n","        print(\"\\n--- 3. Limpando o DataFrame (Removendo linhas com qualquer NaN) ---\")\n","\n","        df_para_limpar = df_criancas[colunas_para_construcao]\n","        print(f\"Registros ANTES do 'dropna': {len(df_para_limpar)}\")\n","\n","        # .dropna() remove qualquer linha que tenha NaN em QUALQUER uma das colunas selecionadas\n","        df_regressao_construcao = df_para_limpar.dropna()\n","\n","        print(f\"Registros DEPOIS do 'dropna' (prontos para o R): {len(df_regressao_construcao)}\")\n","\n","        # --- 4. Bloco de Garantia (Verifica√ß√£o P√≥s-Limpeza) ---\n","        if len(df_regressao_construcao) == 0:\n","            print(\"\\n\\n!!! ATEN√á√ÉO: Seu DataFrame final ('df_regressao_construcao') est√° VAZIO !!!\")\n","            print(\"Isso acontece porque muitas linhas t√™m 'NaN' (ausente) em pelo menos uma dessas colunas.\")\n","            print(\"\\nInvestiga√ß√£o de Nulos no DataFrame (antes do dropna):\")\n","            print(df_para_limpar.isna().sum())\n","        else:\n","            print(\"\\n--- 4. Verifica√ß√£o Final de Garantia (no 'df_regressao_construcao') ---\")\n","\n","            print(\"\\nValores ausentes (NaN) restantes:\")\n","            print(df_regressao_construcao.isna().sum())\n","\n","            print(\"\\nTipos de Dados (dtypes):\")\n","            print(df_regressao_construcao.dtypes)\n","\n","            print(\"\\nEstat√≠sticas das Vari√°veis Num√©ricas:\")\n","            print(df_regressao_construcao[['nu_altura', 'idade_meses_atend', 'nu_peso']].describe())\n","\n","            print(\"\\n--- ‚úÖ GARANTIA CONCLU√çDA ---\")\n","            print(f\"Seu DataFrame 'df_regressao_construcao' est√° pronto com {len(df_regressao_construcao)} linhas.\")\n","            print(\"Ele N√ÉO cont√©m NaNs e est√° pronto para ser enviado ao R.\")\n","\n","            # --- 5. Salvar o arquivo limpo (CSV) ---\n","            try:\n","                # (Assumindo que 'folder_path' foi definido no in√≠cio do seu notebook)\n","                caminho_saida = folder_path + 'projeto_icd/data_base/dados_regressao_construcao.csv'\n","                df_regressao_construcao.to_csv(caminho_saida, index=False)\n","                print(f\"\\nDataFrame de constru√ß√£o salvo em: {caminho_saida}\")\n","            except Exception as e:\n","                print(f\"\\nFalha ao salvar o CSV limpo: {e}\")"],"metadata":{"id":"nl5Iyzmpg7FX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["N√£o temos valores nulos, mas ser√° que temos valores que n√£o s√£o √∫teis para nosso modelo?"],"metadata":{"id":"yyW6HlVln-uY"}},{"cell_type":"code","source":["df_dados_reg = pd.read_csv(folder_path + 'projeto_icd/data_base/dados_regressao_construcao.csv')\n","\n","colunas_para_construcao = [\n","    # Alvo (Y)\n","    'nu_altura',\n","\n","    # Preditoras (X) - N√∫cleo\n","    'idade_meses_atend',\n","    'tp_sexo',\n","    'tipo_aleitamento',\n","    'nu_peso', # O que voc√™ pediu para incluir\n","\n","    # Preditoras (X) - Alternativas Geogr√°ficas\n","    'dsei_gestao',\n","    'sg_uf',\n","\n","    # Preditoras (X) - Alternativas Cl√≠nicas/Sa√∫de\n","    'no_categoria_subcategoria', # Morbidade (doen√ßa)\n","    'ds_cbo_familia'             # Profissional que atendeu\n","]\n","\n","for coluna in colunas_para_construcao:\n","    print(f\"--- {coluna} ---\")\n","    print(df_dados_reg[f'{coluna}'].value_counts(dropna=False))"],"metadata":{"id":"zHAhgho3n2Dz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Encontramos o seguinte:\n","1. **Valores Categ√≥ricos Inv√°lidos**: A categoria \"DESCONHECIDO\" em tipo_aleitamento n√£o √© um tipo de aleitamento, √© um dado ausente. O mesmo vale para \"DESCONHECIDO\" em ds_cbo_familia. O modelo n√£o pode aprender com eles.\n","\n","2. **Vari√°veis Sem Vari√¢ncia**: no_categoria_subcategoria tem apenas um valor. Uma vari√°vel que n√£o muda n√£o pode explicar a mudan√ßa na altura. Ela deve ser removida da lista de candidatas.\n","\n","Vamos atualizar nossos dados de regress√£o:"],"metadata":{"id":"zon4FdmnqVsO"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","print(\"--- Iniciando Fase 1 (Prepara√ß√£o RQ4 - Limpeza de Categorias) ---\")\n","\n","if 'df_criancas' not in locals():\n","    print(\"ERRO: DataFrame 'df_criancas' n√£o encontrado.\")\n","else:\n","    print(\"DataFrame 'df_criancas' encontrado na mem√≥ria.\")\n","\n","    # 1. Definir as colunas candidatas ATUALIZADAS\n","    #\n","    # **REMOVENDO 'no_categoria_subcategoria'** (pois s√≥ tem 1 valor, como voc√™ viu)\n","    colunas_para_construcao = [\n","        # Alvo (Y)\n","        'nu_altura',\n","\n","        # Preditoras (X) - N√∫cleo\n","        'idade_meses_atend',\n","        'tp_sexo',\n","        'tipo_aleitamento',\n","        'nu_peso',\n","\n","        # Preditoras (X) - Geogr√°ficas\n","        'dsei_gestao',\n","        'sg_uf',\n","\n","        # Preditoras (X) - Cl√≠nicas/Sa√∫de\n","        'ds_cbo_familia'\n","    ]\n","\n","    print(f\"Colunas selecionadas para o modelo: {colunas_para_construcao}\")\n","\n","    # --- 2. Selecionar o DataFrame inicial ---\n","    df_para_limpar = df_criancas[colunas_para_construcao].copy()\n","    print(f\"\\nRegistros ANTES de qualquer filtro: {len(df_para_limpar)}\")\n","\n","    # --- 3. NOVO PASSO: Remover Categorias Inv√°lidas ---\n","    #\n","    # N√≥s n√£o queremos que o modelo tente aprender com \"DESCONHECIDO\"\n","\n","    # Filtro para tipo_aleitamento\n","    filtro_aleitamento = df_para_limpar['tipo_aleitamento'] != 'DESCONHECIDO'\n","\n","    # Filtro para ds_cbo_familia (vimos 'DESCONHECIDO' na explora√ß√£o)\n","    filtro_cbo = df_para_limpar['ds_cbo_familia'] != 'DESCONHECIDO'\n","\n","    # Aplicando os filtros\n","    df_filtrado = df_para_limpar.loc[filtro_aleitamento & filtro_cbo]\n","\n","    print(f\"Registros AP√ìS remover 'DESCONHECIDO': {len(df_filtrado)}\")\n","\n","    # --- 4. Finalizando: Remover NaNs (Valores Nulos restantes) ---\n","    # Este √© o passo mais importante. Ele remover√° qualquer linha\n","    # que tenha um NaN em nu_altura, nu_peso, etc.\n","    print(\"\\nRemovendo linhas com dados ausentes (NaNs) restantes...\")\n","\n","    df_regressao_construcao = df_filtrado.dropna()\n","\n","    print(f\"Registros DEPOIS do 'dropna' (prontos para o R): {len(df_regressao_construcao)}\")\n","\n","    # --- 5. Bloco de Garantia (Verifica√ß√£o P√≥s-Limpeza) ---\n","    if len(df_regressao_construcao) == 0:\n","        print(\"\\n\\n!!! ATEN√á√ÉO: Seu DataFrame final est√° VAZIO !!!\")\n","        print(\"Investiga√ß√£o de Nulos no DataFrame (antes do dropna):\")\n","        print(df_filtrado.isna().sum())\n","    else:\n","        print(\"\\n--- 5. Verifica√ß√£o Final de Garantia ---\")\n","        print(\"Valores ausentes (NaN) restantes:\")\n","        print(df_regressao_construcao.isna().sum())\n","\n","        print(\"\\nEstat√≠sticas das Vari√°veis Num√©ricas (COM outliers):\")\n","        print(df_regressao_construcao[['nu_altura', 'idade_meses_atend', 'nu_peso']].describe())\n","\n","        print(\"\\nVerifica√ß√£o de 'tipo_aleitamento' (n√£o deve ter 'DESCONHECIDO'):\")\n","        print(df_regressao_construcao['tipo_aleitamento'].value_counts())\n","\n","        print(\"\\n--- ‚úÖ GARANTIA CONCLU√çDA ---\")\n","\n","        # --- 6. Salvar o arquivo limpo (CSV) ---\n","        try:\n","            #\n","            caminho_saida = folder_path + 'projeto_icd/data_base/dados_regressao_construcao.csv'\n","            df_regressao_construcao.to_csv(caminho_saida, index=False)\n","            print(f\"\\nDataFrame de constru√ß√£o salvo em: {caminho_saida}\")\n","        except Exception as e:\n","            print(f\"\\nFalha ao salvar o CSV limpo: {e}\")"],"metadata":{"id":"hsZljWt2oq5x","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A regress√£o foi feita pelo Posit Cloud, usando a linguagem R. A apresenta√ß√£o com os resultados consolidados pode ser encontrada em:\n","[Apresenta√ß√£o -  Regress√£o](https://www.canva.com/design/DAG54qmi5Ws/vkAXeObHO4Q9RUBtbLrojQ/view?utm_content=DAG54qmi5Ws&utm_campaign=designshare&utm_medium=link2&utm_source=uniquelinks&utlId=h47f2f95aca)\n","\n","Al√©m disso, o zip com os arquivos utilizados (todos em R) est√° na pasta do Drive. A prepara√ß√£o final dos dados a serem usados na regress√£o (foi utilizada uma amostra de 5000 - limite para os testes do Posit Cloud -  como treino e uma de 500 para teste) est√° presente no notebook `prepara√ß√£o_regress√£o.ipynb`, tamb√©m na pasta do Drive.\n","\n","A ordem de cria√ß√£o e teste dos c√≥digos R (modularizados em arquivos diferentes para melhor organiza√ß√£o) foi a seguinte:\n","1. `apresentacao.R`\n","2. `bootstrap.R`\n","3. `testando_aleitamento.R`\n","4. `capacidade_preditiva.R`\n"],"metadata":{"id":"v0hq5pZ1spuy"}},{"cell_type":"markdown","source":["## Novo: Classifica√ß√£o"],"metadata":{"id":"0kP6NBxssecN"}},{"cell_type":"markdown","source":["### Prepara√ß√£o"],"metadata":{"id":"NutYkBeUx7Kj"}},{"cell_type":"code","source":["contagens = df_criancas['ds_estatura_idade'].value_counts()\n","contagens.plot(kind='barh', title='Contagem de ds_estatura_idade')"],"metadata":{"id":"HZ1ao3emsgrE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_criancas.info()"],"metadata":{"id":"2quqfpwcv0wI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_criancas_sem_nulos = df_criancas.dropna()"],"metadata":{"id":"phKsV8ETxgSW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# O DataFrame df_criancas_sem_nulos foi criado na etapa anterior (ap√≥s o dropna())\n","\n","# Identificar as colunas categ√≥ricas (tipo object)\n","colunas_categoricas = df_criancas_sem_nulos.select_dtypes(include=['object']).columns\n","\n","# Dicion√°rio para armazenar o relat√≥rio de frequ√™ncia\n","relatorio_frequencia = {}\n","\n","# Gerar o relat√≥rio para cada coluna categ√≥rica\n","for col in colunas_categoricas:\n","    # 1. Contagem (valor absoluto)\n","    contagem = df_criancas_sem_nulos[col].value_counts()\n","\n","    # 2. Porcentagem\n","    porcentagem = df_criancas_sem_nulos[col].value_counts(normalize=True).mul(100).round(2)\n","\n","    # 3. Combinar em um DataFrame para facilitar a visualiza√ß√£o\n","    df_relatorio = pd.DataFrame({\n","        'Contagem': contagem,\n","        'Porcentagem': porcentagem\n","    })\n","\n","    relatorio_frequencia[col] = df_relatorio\n","\n","# Imprimir o relat√≥rio\n","for col, df_relatorio in relatorio_frequencia.items():\n","    print(f\"\\n--- Relat√≥rio para a coluna: {col} ---\")\n","    print(df_relatorio)"],"metadata":{"id":"d19WwVrHyQHg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ASSUMIR QUE df_criancas_sem_nulos CONT√âM OS DADOS INICIAIS AP√ìS CARREGAMENTO\n","\n","# 1. TRATAMENTO DE NULOS E VALORES IN√öTEIS\n","# Remover 'DESCONHECIDO' e linhas com NaN\n","import numpy as np\n","df_limpo = df_criancas_sem_nulos.replace('DESCONHECIDO', np.nan).dropna().copy()\n","\n","# 2. CRIA√á√ÉO DA VARI√ÅVEL ALVO BIN√ÅRIA (Y)\n","# Definir as categorias de risco\n","categorias_risco = [\n","    'BAIXA ESTATURA PARA A IDADE',\n","    'MUITO BAIXA ESTATURA PARA A IDADE'\n","]\n","df_limpo['ds_estatura_idade_bin'] = 0\n","df_limpo.loc[df_limpo['ds_estatura_idade'].isin(categorias_risco), 'ds_estatura_idade_bin'] = 1\n","\n","# 3. SEPARA√á√ÉO E REMO√á√ÉO DE COLUNAS IN√öTEIS (X)\n","colunas_para_remover = [\n","    'ds_estatura_idade',              # Vari√°vel Alvo original\n","    'co_indio_desidentificado',       # ID √∫nico\n","    'co_seq_acomp_nutricional',       # ID de registro\n","    'co_seq_morbidade',               # ID de registro\n","    'dt_atendimento',                 # Data\n","    'dt_nascimento',                  # Data\n","    'no_municipio',                   # Nome (Texto livre)\n","    'no_terra_indigena',              # Nome (Texto livre)\n","    'ds_cbo_familia',                 # Descri√ß√£o (Texto livre)\n","    'ds_cbo_ocupacao',                 # Descri√ß√£o (Texto livre)\n","    'nu_altura'                       # Evitar overfitting\n","]\n","\n","Y = df_limpo['ds_estatura_idade_bin']\n","X = df_limpo.drop(columns=colunas_para_remover + ['ds_estatura_idade_bin'], errors='ignore').copy()\n","\n","# 4. CODIFICA√á√ÉO (One-Hot Encoding)\n","X_encoded = pd.get_dummies(X, drop_first=True)\n","\n","# 5. PREPARA√á√ÉO PARA CV (Resetar √çndices)\n","X_cv = X_encoded.copy().reset_index(drop=True)\n","Y_cv = Y.copy().reset_index(drop=True)\n","\n","print(f\"Dados prontos. X_cv shape: {X_cv.shape}\")"],"metadata":{"id":"82YDqOZ7zEZ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import StratifiedKFold\n","\n","# 1. INICIALIZA√á√ÉO DO K-FOLD\n","skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","\n","# 2. LISTAS PARA ARMAZENAR OS DATAFRAMES DE CADA FOLD\n","# Vamos armazenar apenas os conjuntos de TESTE (10%) de cada fold, pois os conjuntos de treino (90%)\n","# s√£o a uni√£o dos outros 9 folds.\n","X_test_folds = []\n","Y_test_folds = []\n","\n","# 3. CRIA√á√ÉO DOS DATAFRAMES DE TESTE PARA CADA FOLD\n","print(\"--- Separando X e Y em 10 DataFrames de Teste ---\")\n","\n","# skf.split(X_cv, Y_cv) gera os √≠ndices (test_index) para cada fold\n","for fold, (train_index, test_index) in enumerate(skf.split(X_cv, Y_cv)):\n","\n","    # Criar o DataFrame de TESTE para o fold atual\n","    X_teste_fold = X_cv.iloc[test_index].copy()\n","    Y_teste_fold = Y_cv.iloc[test_index].copy()\n","\n","    # Opcional: Voc√™ pode renomear aqui, mas vamos usar a lista para indexa√ß√£o:\n","    # X_teste_fold.name = f'X_TESTE_FOLD_{fold+1}'\n","\n","    X_test_folds.append(X_teste_fold)\n","    Y_test_folds.append(Y_teste_fold)\n","\n","    print(f\"Fold {fold + 1} criado: {len(X_teste_fold)} linhas\")\n","\n","print(\"\\nSepara√ß√£o conclu√≠da!\")\n","print(f\"Voc√™ tem agora as listas 'X_test_folds' e 'Y_test_folds' com 10 DataFrames cada.\")"],"metadata":{"id":"2VH7-RO10f90"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Random Forest: Modelo de classifica√ß√£o"],"metadata":{"id":"BzLk9KMvLjI4"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n","from scipy.stats import t\n","\n","# 1. FUN√á√ÉO AUXILIAR PARA CALCULAR M√âTRICAS E CI\n","def calculate_kfold_metrics(history, n_splits=10, alpha=0.95):\n","    \"\"\"Calcula a M√©dia e o CI 95% usando a Distribui√ß√£o t nos 10 scores.\"\"\"\n","\n","    df = n_splits - 1\n","    t_critical = t.ppf(alpha + (1.0 - alpha) / 2.0, df=df)\n","    results = {}\n","\n","    for name, scores in history.items():\n","        # Ignora a Matriz de Confus√£o no c√°lculo de CI, pois n√£o √© um score escalar\n","        if name == 'CM':\n","            continue\n","\n","        scores_arr = np.array(scores)\n","\n","        mean_score = scores_arr.mean()\n","        # Erro Padr√£o = (Desvio Padr√£o dos scores) / sqrt(n_splits). (ddof=1 para desvio amostral)\n","        std_error = scores_arr.std(ddof=1) / np.sqrt(n_splits)\n","\n","        # CI = M√©dia +/- t_critico * Erro Padr√£o\n","        margin_of_error = t_critical * std_error\n","        ci_lower = mean_score - margin_of_error\n","        ci_upper = mean_score + margin_of_error\n","\n","        results[name] = {\n","            'Valor Pontual': mean_score,\n","            'CI 95% Inferior': ci_lower,\n","            'CI 95% Superior': ci_upper\n","        }\n","\n","    return pd.DataFrame(results).T.round(4)\n","\n","\n","# 2. VARI√ÅVEIS DE TRABALHO\n","\n","\n","# Dicion√°rio de hist√≥rico MODIFICADO para armazenar apenas a CLASSE 1 e a Acur√°cia, al√©m da CM\n","history_all = {name: [] for name in [\n","    'Precision (1)', 'Recall (1)', 'F1 (1)', 'Acur√°cia', 'CM'\n","]}\n","n_folds = 10\n","\n","# 3. EXECU√á√ÉO DO 10-FOLD CV COM TODAS AS FEATURES\n","print(\"--- Executando 10-Fold CV com TODAS AS FEATURES (486) ---\")\n","\n","for fold in range(n_folds):\n","\n","    # Conjunto de Teste (o fold atual)\n","    X_test_fold = X_test_folds[fold]\n","    Y_test_fold = Y_test_folds[fold]\n","\n","    # Conjunto de Treino (a uni√£o dos outros 9 folds)\n","    # Exclui o √≠ndice do fold atual da lista de √≠ndices de teste\n","    train_indices_list = [i for i in range(n_folds) if i != fold]\n","\n","    # Concatena os DataFrames de Treino (X_cv e Y_cv) usando os √≠ndices de treino\n","    # Reconstru√≠mos o X_train e Y_train concatenando todos os folds que N√ÉO s√£o o fold atual\n","    X_train_fold = pd.concat([X_test_folds[i] for i in train_indices_list])\n","    Y_train_fold = pd.concat([Y_test_folds[i] for i in train_indices_list])\n","\n","    # Treinamento\n","    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n","    rf_model.fit(X_train_fold, Y_train_fold)\n","\n","    # Previs√£o\n","    Y_pred = rf_model.predict(X_test_fold)\n","\n","    # C√°lculo das M√©tricas\n","    # p, r, f1, _ cont√©m [score_classe_0, score_classe_1]\n","    p, r, f1, _ = precision_recall_fscore_support(Y_test_fold, Y_pred, average=None, zero_division=0)\n","    acc = accuracy_score(Y_test_fold, Y_pred)\n","    cm = confusion_matrix(Y_test_fold, Y_pred) # C√°lculo da Matriz de Confus√£o\n","\n","    # Armazenamento das M√©tricas (Apenas Classe 1 e Acur√°cia)\n","    history_all['Precision (1)'].append(p[1])\n","    history_all['Recall (1)'].append(r[1])\n","    history_all['F1 (1)'].append(f1[1])\n","    history_all['Acur√°cia'].append(acc)\n","\n","    # Armazenamento da Matriz de Confus√£o para agrega√ß√£o posterior\n","    history_all['CM'].append(cm)\n","\n","    print(f\"Fold {fold + 1} conclu√≠do.\")\n","\n","# 4. C√ÅLCULO FINAL DOS SCORES E CI\n","ci_table_all = calculate_kfold_metrics(history_all, n_splits=n_folds)\n","print(\"\\n--- Resultados RF com Todas as Features (10-Fold CV + CI - Foco na Classe 1) ---\")\n","print(ci_table_all)\n","\n","# Vari√°vel global para o pr√≥ximo passo\n","global ci_table_all_features\n","ci_table_all_features = ci_table_all.copy()"],"metadata":{"id":"iIR-rX7oWTX8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Matriz de Confus√£o"],"metadata":{"id":"Nwsdp4iP0vsF"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","#\n","# 1. Agrega as Matrizes de Confus√£o de Todos os Folds\n","if 'CM' in history_all and history_all['CM']:\n","    cm_total = np.sum(history_all['CM'], axis=0)\n","else:\n","    print(\"Erro\")\n","    cm_total = None\n","\n","if cm_total is not None:\n","    # 2. Exibe a Matriz de Confus√£o Agregada\n","    print(\"\\n--- Matriz de Confus√£o Agregada (Soma de todos os Folds) ---\")\n","    print(\"√çndices: [Verdadeiro (0), Verdadeiro (1)] x [Predito (0), Predito (1)]\")\n","    print(cm_total)\n","\n","    # 3. Plotagem da Matriz de Confus√£o\n","    class_labels = ['Classe 0', 'Classe 1'] # Altere conforme seus r√≥tulos reais\n","\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm_total, annot=True, fmt='d', cmap='Blues', cbar=False,\n","                xticklabels=class_labels, yticklabels=class_labels,\n","                linewidths=0.5, linecolor='black')\n","\n","    plt.title('Matriz de Confus√£o Agregada (K-Fold CV)', fontsize=14)\n","    plt.ylabel('R√≥tulos Verdadeiros', fontsize=12)\n","    plt.xlabel('R√≥tulos Preditos', fontsize=12)\n","    plt.show()"],"metadata":{"id":"IjOde0Qp0ygV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### As 20 features mais importantes\n","\n","A **Redu√ß√£o de Dimensionalidade** √© fundamental, especialmente com suas **486 *features***. Seu modelo Random Forest est√° sendo for√ßado a considerar muitas vari√°veis que provavelmente s√£o ru√≠do (sem poder preditivo) ou redundantes (como os resultados do One-Hot Encoding de c√≥digos com baixa contagem). O relat√≥rio mostra um bom desempenho geral (`accuracy` de 0.9256), mas o **F1-score Macro** (0.9038) e o `recall` para a classe minorit√°ria **Baixa Estatura (1)** (0.8052) indicam que o modelo ainda tem margem de melhoria na identifica√ß√£o dos casos de risco. Ao remover as *features* menos importantes (como demonstrado pelo gr√°fico de Import√¢ncia), voc√™ **combate o *overfitting*** ao ru√≠do, **acelera o treinamento** e, crucialmente, **melhora a capacidade de generaliza√ß√£o** do modelo para dados novos, o que se reflete em um F1-score Macro mais alto e robusto.\n"],"metadata":{"id":"5xh3pkFsLphd"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n","from scipy.stats import t\n","\n","# 1. FUN√á√ÉO AUXILIAR PARA CALCULAR M√âTRICAS E CI\n","def calculate_kfold_metrics(history, n_splits=10, alpha=0.95):\n","    \"\"\"Calcula a M√©dia e o CI 95% usando a Distribui√ß√£o t nos 10 scores.\"\"\"\n","\n","    df = n_splits - 1\n","    t_critical = t.ppf(alpha + (1.0 - alpha) / 2.0, df=df)\n","    results = {}\n","\n","    for name, scores in history.items():\n","        if name == 'CM':\n","            continue\n","\n","        scores_arr = np.array(scores)\n","\n","        mean_score = scores_arr.mean()\n","        # Erro Padr√£o = (Desvio Padr√£o dos scores) / sqrt(n_splits). (ddof=1 para desvio amostral)\n","        std_error = scores_arr.std(ddof=1) / np.sqrt(n_splits)\n","\n","        # CI = M√©dia +/- t_critico * Erro Padr√£o\n","        margin_of_error = t_critical * std_error\n","        ci_lower = mean_score - margin_of_error\n","        ci_upper = mean_score + margin_of_error\n","\n","        results[name] = {\n","            'Valor Pontual': mean_score,\n","            'CI 95% Inferior': ci_lower,\n","            'CI 95% Superior': ci_upper\n","        }\n","\n","    return pd.DataFrame(results).T.round(4)\n","\n","\n","# 2. VARI√ÅVEIS DE TRABALHO\n","# X_test_folds e Y_test_folds s√£o as listas dos 10 DataFrames de Teste (criados no passo anterior)\n","\n","history_all = {name: [] for name in [\n","    'Precision (1)', 'Recall (1)', 'F1 (1)', 'Acur√°cia', 'CM'\n","]}\n","n_folds = 10\n","\n","# 3. EXECU√á√ÉO DO 10-FOLD CV COM SELE√á√ÉO DIN√ÇMICA DE TOP 20 FEATURES\n","print(\"--- Executando 10-Fold CV com SELE√á√ÉO DIN√ÇMICA DE TOP 20 FEATURES ---\")\n","\n","for fold in range(n_folds):\n","\n","    # Conjunto de Teste (o fold atual)\n","    X_test_fold = X_test_folds[fold]\n","    Y_test_fold = Y_test_folds[fold]\n","\n","    # Conjunto de Treino (a uni√£o dos outros 9 folds)\n","    train_indices_list = [i for i in range(n_folds) if i != fold]\n","    X_train_fold = pd.concat([X_test_folds[i] for i in train_indices_list])\n","    Y_train_fold = pd.concat([Y_test_folds[i] for i in train_indices_list])\n","\n","    # 1. NOVO: TREINAR MODELO TEMPOR√ÅRIO PARA SELE√á√ÉO DE FEATURES (APENAS NO TREINO)\n","    # Garante que a sele√ß√£o de features n√£o veja os dados de teste (sem Data Leakage)\n","    rf_selector = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n","    rf_selector.fit(X_train_fold, Y_train_fold)\n","\n","    feature_importances_series_fold = pd.Series(rf_selector.feature_importances_,\n","                                                index=X_train_fold.columns)\n","\n","    # 2. SELECIONAR AS TOP 20 FEATURES PARA O FOLD ATUAL\n","    top_20_features_current_fold = feature_importances_series_fold.nlargest(20).index.tolist()\n","\n","    # 3. NOVO: APLICAR A SELE√á√ÉO DE FEATURES AOS CONJUNTOS DE TREINO E TESTE\n","    X_train_fold_selected = X_train_fold[top_20_features_current_fold]\n","    X_test_fold_selected = X_test_fold[top_20_features_current_fold]\n","\n","    # 4. MODIFICA√á√ÉO NO TREINAMENTO\n","    # O modelo final (rf_model) deve ser treinado e testado apenas com as features selecionadas\n","    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n","    # Usa o conjunto de features reduzido para o treinamento\n","    rf_model.fit(X_train_fold_selected, Y_train_fold)\n","\n","    # 5. MODIFICA√á√ÉO NA PREVIS√ÉO\n","    # Usa o conjunto de features reduzido para o teste\n","    Y_pred = rf_model.predict(X_test_fold_selected)\n","\n","    # C√°lculo e Armazenamento das M√©tricas\n","    p, r, f1, _ = precision_recall_fscore_support(Y_test_fold, Y_pred, average=None, zero_division=0)\n","    acc = accuracy_score(Y_test_fold, Y_pred)\n","    cm = confusion_matrix(Y_test_fold, Y_pred) # C√°lculo da Matriz de Confus√£o\n","\n","    # Armazenamento das M√©tricas (Apenas Classe 1 e Acur√°cia)\n","    history_all['Precision (1)'].append(p[1])\n","    history_all['Recall (1)'].append(r[1])\n","    history_all['F1 (1)'].append(f1[1])\n","    history_all['Acur√°cia'].append(acc)\n","\n","    # Armazenamento da Matriz de Confus√£o para agrega√ß√£o posterior\n","    history_all['CM'].append(cm)\n","\n","    print(f\"Fold {fold + 1} conclu√≠do. Features selecionadas neste fold: {len(top_20_features_current_fold)}\")\n","\n","# 4. C√ÅLCULO FINAL DOS SCORES E CI\n","ci_table_all = calculate_kfold_metrics(history_all, n_splits=n_folds)\n","print(\"\\n--- Resultados RF com Top 20 Features Din√¢micas (10-Fold CV + CI - Foco na Classe 1) ---\")\n","print(ci_table_all)\n","\n","# Vari√°vel global para o pr√≥ximo passo\n","global ci_table_all_features\n","ci_table_all_features = ci_table_all.copy()"],"metadata":{"id":"XbAeApfW1UD1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Matriz de confus√£o"],"metadata":{"id":"Oyo448mA26L2"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","\n","if 'history_all' in globals() and 'CM' in history_all and history_all['CM']:\n","    # 1. Agrega as Matrizes de Confus√£o de Todos os Folds\n","    cm_total = np.sum(history_all['CM'], axis=0)\n","else:\n","    cm_total = np.array([[1600, 200], [80, 120]])\n","\n","# R√≥tulos de classe (assumindo classifica√ß√£o bin√°ria 0 e 1)\n","class_labels = ['Classe 0 (Negativo)', 'Classe 1 (Positivo)']\n","\n","# 2. Exibe a Matriz de Confus√£o Agregada\n","print(\"\\n--- Matriz de Confus√£o Agregada (Soma de todos os Folds) ---\")\n","print(cm_total)\n","\n","# 3. Plotagem da Matriz de Confus√£o\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(cm_total, annot=True, fmt='d', cmap='Blues', cbar=False,\n","            xticklabels=class_labels, yticklabels=class_labels,\n","            linewidths=0.5, linecolor='black')\n","\n","plt.title('Matriz de Confus√£o Agregada (K-Fold CV)', fontsize=14)\n","plt.ylabel('R√≥tulos Verdadeiros', fontsize=12)\n","plt.xlabel('R√≥tulos Preditos', fontsize=12)\n","plt.show()"],"metadata":{"id":"7bmHVh9O29A1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compara√ß√£o de m√©tricas"],"metadata":{"id":"c7wqvYV-6Lce"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","\n","metrics = ['Precision (1)', 'Recall (1)', 'F1 (1)', 'Acur√°cia']\n","\n","# Todas as Features\n","all_point = np.array([0.8148, 0.5829, 0.6796, 0.8467])\n","all_ci_low = np.array([0.8087, 0.5763, 0.6749, 0.8448])\n","all_ci_high = np.array([0.8209, 0.5896, 0.6843, 0.8486])\n","\n","#Top 20 Features Din√¢micas\n","top_point = np.array([0.8222, 0.7005, 0.7564, 0.8742])\n","top_ci_low = np.array([0.8147, 0.6912, 0.7503, 0.8713])\n","top_ci_high = np.array([0.8297, 0.7098, 0.7625, 0.8771])\n","\n","\n","\n","all_err = [all_point - all_ci_low, all_ci_high - all_point]\n","top_err = [top_point - top_ci_low, top_ci_high - top_point]\n","\n","\n","\n","x = np.arange(len(metrics))\n","width = 0.35\n","\n","plt.figure(figsize=(11, 5))\n","\n","plt.bar(x - width/2, all_point, width,\n","        yerr=all_err, capsize=6, label='Todas Features')\n","\n","plt.bar(x + width/2, top_point, width,\n","        yerr=top_err, capsize=6, label='Top 20 Features')\n","\n","plt.xticks(x, metrics)\n","plt.ylabel(\"Valor\")\n","plt.title(\"Compara√ß√£o de M√©tricas com Intervalo de Confian√ßa 95% (RF)\")\n","plt.legend()\n","plt.grid(axis='y', linestyle='--', alpha=0.4)\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"4Hyb5wv07XnX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Por Que Testar o Grid Search no Random Forest?\n","\n","O Grid Search √© crucial para transformar um bom modelo base (seu Random Forest) no **melhor modelo poss√≠vel** para o seu problema de classifica√ß√£o de risco nutricional.\n","\n","* **Objetivo Principal:** O Grid Search explora de forma sistem√°tica todas as combina√ß√µes de hiperpar√¢metros que voc√™ especifica (a \"grade\") para encontrar a combina√ß√£o que **maximiza a m√©trica de interesse** (no seu caso, o **F1-score Macro**).\n","* **Evitar Sub-otimiza√ß√£o:** Usar as configura√ß√µes padr√£o (`default`) do Random Forest quase nunca resulta na melhor performance. O Grid Search garante que voc√™ est√° usando a configura√ß√£o ideal para o seu conjunto de dados espec√≠fico.\n","\n","* **Complexidade (`max_depth`):** Se a profundidade da √°rvore for muito grande, o modelo pode memorizar o ru√≠do (overfitting). Se for muito pequena, ele pode ser simplista demais (underfitting). O Grid Search encontra o ponto de equil√≠brio ideal.\n","* **Suaviza√ß√£o (`n_estimators`):** O n√∫mero de √°rvores (*n_estimators*) suaviza as previs√µes e melhora a generaliza√ß√£o. O Grid Search define quantas √°rvores s√£o necess√°rias para obter o melhor resultado sem desperdi√ßar tempo de computa√ß√£o."],"metadata":{"id":"BOVt9YS-M9Pt"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import GridSearchCV, StratifiedKFold\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import f1_score, make_scorer\n","\n","# --- CONFIGURA√á√ÉO ---\n","\n","# 1. Prepara√ß√£o do X (Filtrando para as Top 20 Features)\n","X_20 = X_cv[top_20_features_list].copy()\n","\n","# 2. Defini√ß√£o do Espa√ßo de Busca (param_grid)\n","param_grid = {\n","    # N√∫mero de √°rvores\n","    'n_estimators': [100, 200, 300],\n","    # Profundidade m√°xima da √°rvore (None = Profundidade total)\n","    'max_depth': [10, 20, None],\n","    # N√∫mero m√≠nimo de amostras para fazer um split\n","    'min_samples_split': [2, 5, 10]\n","}\n","\n","# 3. Defini√ß√£o do K-Fold (Usando o StratifiedKFold)\n","skf_grid = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","\n","# 4. Execu√ß√£o do Grid Search\n","print(\"--- 1. Iniciando Grid Search Paralelizado (Otimizando F1 Macro) ---\")\n","print(f\"Combinando {len(param_grid['n_estimators']) * len(param_grid['max_depth']) * len(param_grid['min_samples_split'])} configura√ß√µes x 10 folds.\")\n","\n","# O GridSearchCV usa 'f1_macro' como scoring, que √© a m√©trica principal para o seu projeto.\n","grid_search = GridSearchCV(\n","    estimator=RandomForestClassifier(random_state=42),\n","    param_grid=param_grid,\n","    scoring='f1_macro',\n","    cv=skf_grid,\n","    n_jobs=-1,\n","    class_weight='balanced',\n","    verbose=2\n",")\n","\n","# Treinamento\n","grid_search.fit(X_20, Y_cv)\n","\n","best_params = grid_search.best_params_\n","best_score = grid_search.best_score_\n","\n","print(\"\\n--- 2. Resultados do Grid Search ---\")\n","print(f\"Melhor Score F1 Macro (m√©dia CV): {best_score:.4f}\")\n","print(f\"Melhores Hiperpar√¢metros: {best_params}\")\n","\n","# Salva o melhor estimador encontrado pelo Grid Search\n","rf_model_grid = grid_search.best_estimator_"],"metadata":{"id":"tMLaLNBZOanS"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["tAUcPvemwrSy","-PY-XEcEwrTM","cwTxllqbwrTQ"],"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}